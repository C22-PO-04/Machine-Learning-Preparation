{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd64eebc",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modelling</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Utilities\" data-toc-modified-id=\"Utilities-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Utilities</a></span></li></ul></li><li><span><a href=\"#Optimizing-&quot;cool-stuff&quot;-category\" data-toc-modified-id=\"Optimizing-&quot;cool-stuff&quot;-category-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Optimizing \"cool stuff\" category</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Model\" data-toc-modified-id=\"Training-Model-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Training Model</a></span></li><li><span><a href=\"#Price-Optimization-Demonstration\" data-toc-modified-id=\"Price-Optimization-Demonstration-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Price Optimization Demonstration</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89624cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_row', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e4a283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>sales</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>2</td>\n",
       "      <td>111285.5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telefonia</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>181684.4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38228</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38229</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38230</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38231</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38233 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                product_category_name  \\\n",
       "0                                    moveis_decoracao   \n",
       "1                                           telefonia   \n",
       "2                                    moveis_decoracao   \n",
       "3                                    moveis_decoracao   \n",
       "4                                    moveis_decoracao   \n",
       "...                                               ...   \n",
       "38228  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38229  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38230  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38231  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38232  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "\n",
       "      order_purchase_timestamp  sales        price  \n",
       "0                   2016-09-04      2  111285.5364  \n",
       "1                   2016-09-05      1  181684.4400  \n",
       "2                   2016-09-05      1  122110.2648  \n",
       "3                   2016-09-06      1  122110.2648  \n",
       "4                   2016-09-07      1  122110.2648  \n",
       "...                        ...    ...          ...  \n",
       "38228               2018-08-30      1  442760.4000  \n",
       "38229               2018-08-31      1  442760.4000  \n",
       "38230               2018-09-01      1  442760.4000  \n",
       "38231               2018-09-02      1  442760.4000  \n",
       "38232               2018-09-03      1  442760.4000  \n",
       "\n",
       "[38233 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/prepared/interpolated_demand_history_by_category.csv')\n",
    "data['order_purchase_timestamp'] = pd.to_datetime(data['order_purchase_timestamp'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb63570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[['sales', 'price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c9021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(scaler, \"../model/demand_forecasting/scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15471c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>sales</th>\n",
       "      <th>price</th>\n",
       "      <th>scaled_sales</th>\n",
       "      <th>scaled_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>2</td>\n",
       "      <td>111285.5364</td>\n",
       "      <td>-0.542631</td>\n",
       "      <td>-0.643513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>telefonia</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>181684.4400</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.510565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.623071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.623071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>122110.2648</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.623071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38228</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.017522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38229</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.017522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38230</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.017522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38231</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-02</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.017522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>moveis_cozinha_area_de_servico_jantar_e_jardim</td>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>1</td>\n",
       "      <td>442760.4000</td>\n",
       "      <td>-0.553409</td>\n",
       "      <td>-0.017522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38233 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                product_category_name  \\\n",
       "0                                    moveis_decoracao   \n",
       "1                                           telefonia   \n",
       "2                                    moveis_decoracao   \n",
       "3                                    moveis_decoracao   \n",
       "4                                    moveis_decoracao   \n",
       "...                                               ...   \n",
       "38228  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38229  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38230  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38231  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "38232  moveis_cozinha_area_de_servico_jantar_e_jardim   \n",
       "\n",
       "      order_purchase_timestamp  sales        price  scaled_sales  scaled_price  \n",
       "0                   2016-09-04      2  111285.5364     -0.542631     -0.643513  \n",
       "1                   2016-09-05      1  181684.4400     -0.553409     -0.510565  \n",
       "2                   2016-09-05      1  122110.2648     -0.553409     -0.623071  \n",
       "3                   2016-09-06      1  122110.2648     -0.553409     -0.623071  \n",
       "4                   2016-09-07      1  122110.2648     -0.553409     -0.623071  \n",
       "...                        ...    ...          ...           ...           ...  \n",
       "38228               2018-08-30      1  442760.4000     -0.553409     -0.017522  \n",
       "38229               2018-08-31      1  442760.4000     -0.553409     -0.017522  \n",
       "38230               2018-09-01      1  442760.4000     -0.553409     -0.017522  \n",
       "38231               2018-09-02      1  442760.4000     -0.553409     -0.017522  \n",
       "38232               2018-09-03      1  442760.4000     -0.553409     -0.017522  \n",
       "\n",
       "[38233 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['scaled_sales'] = scaled_data[:,0]\n",
    "data['scaled_price'] = scaled_data[:,1]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb574f",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d2a82",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf47777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 16:03:05.537553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 16:03:05.537705: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install wandb\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67443e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(ds, n_sample=3):\n",
    "    for x in ds.take(n_sample):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d56b5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    plt.plot(pd.DataFrame(history.history)[['loss', 'val_loss']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb319d6",
   "metadata": {},
   "source": [
    "## Optimizing \"cool stuff\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4cfeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_category_name\n",
       "cama_mesa_banho                                   218660\n",
       "esporte_lazer                                     187600\n",
       "moveis_decoracao                                  164027\n",
       "beleza_saude                                      140903\n",
       "utilidades_domesticas                             126172\n",
       "informatica_acessorios                            119338\n",
       "relogios_presentes                                103796\n",
       "brinquedos                                         75586\n",
       "telefonia                                          74968\n",
       "automotivo                                         74474\n",
       "cool_stuff                                         68547\n",
       "bebes                                              61847\n",
       "perfumaria                                         53017\n",
       "fashion_bolsas_e_acessorios                        51976\n",
       "pet_shop                                           50971\n",
       "papelaria                                          48411\n",
       "ferramentas_jardim                                 44990\n",
       "eletronicos                                        44092\n",
       "moveis_escritorio                                  36673\n",
       "malas_acessorios                                   18700\n",
       "instrumentos_musicais                              17664\n",
       "eletrodomesticos                                   16500\n",
       "eletroportateis                                    16406\n",
       "consoles_games                                     15184\n",
       "construcao_ferramentas_construcao                  14299\n",
       "moveis_sala                                        13115\n",
       "livros_interesse_geral                             11549\n",
       "market_place                                       11239\n",
       "casa_conforto                                      11228\n",
       "fashion_calcados                                    8131\n",
       "eletrodomesticos_2                                  7747\n",
       "casa_construcao                                     7217\n",
       "construcao_ferramentas_jardim                       6761\n",
       "alimentos                                           5924\n",
       "moveis_cozinha_area_de_servico_jantar_e_jardim      5875\n",
       "alimentos_bebidas                                   5379\n",
       "climatizacao                                        4962\n",
       "telefonia_fixa                                      4587\n",
       "audio                                               4412\n",
       "industria_comercio_e_negocios                       4312\n",
       "agro_industria_e_comercio                           4291\n",
       "bebidas                                             3745\n",
       "fashion_underwear_e_moda_praia                      3450\n",
       "construcao_ferramentas_seguranca                    3270\n",
       "livros_tecnicos                                     3062\n",
       "sinalizacao_e_seguranca                             2758\n",
       "artigos_de_natal                                    2282\n",
       "construcao_ferramentas_iluminacao                   2100\n",
       "moveis_quarto                                       1993\n",
       "artes                                               1918\n",
       "tablets_impressao_imagem                            1773\n",
       "fashion_roupa_masculina                             1394\n",
       "construcao_ferramentas_ferramentas                  1358\n",
       "pcs                                                 1242\n",
       "fashion_roupa_feminina                              1110\n",
       "dvds_blu_ray                                        1024\n",
       "cine_foto                                            801\n",
       "portateis_casa_forno_e_cafe                          783\n",
       "artigos_de_festas                                    591\n",
       "moveis_colchao_e_estofado                            554\n",
       "casa_conforto_2                                      553\n",
       "livros_importados                                    546\n",
       "la_cuisine                                           504\n",
       "flores                                               483\n",
       "fashion_esporte                                      467\n",
       "fraldas_higiene                                      449\n",
       "fashion_roupa_infanto_juvenil                        415\n",
       "musica                                               412\n",
       "pc_gamer                                             333\n",
       "cds_dvds_musicais                                    290\n",
       "portateis_cozinha_e_preparadores_de_alimentos        104\n",
       "artes_e_artesanato                                    76\n",
       "seguros_e_servicos                                     2\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('product_category_name').sales.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6aed8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanfredmichael\u001b[0m (\u001b[33manakbangkit\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2022-06-03 16:03:55.929116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 16:03:55.929151: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/manfred/Projects/bangkit/CompanyBasedCapstone/Modelling/wandb/run-20220603_160331-t0ocrbq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/anakbangkit/cateogory-discount-optimization/runs/t0ocrbq3\" target=\"_blank\">lilac-firefly-28</a></strong> to <a href=\"https://wandb.ai/anakbangkit/cateogory-discount-optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"cateogory-discount-optimization\", entity=\"anakbangkit\", reinit=True)\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c862f",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce367734",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.product_category_name = 'informatica_acessorios'\n",
    "config.test_size = 0.2\n",
    "config.valid_size = 0.2\n",
    "config.window_size = 30\n",
    "config.batch_size = 8\n",
    "config.buffer_size = 100_000\n",
    "config.stateful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e28ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_product = data[data.product_category_name==config.product_category_name]\n",
    "poi_product = poi_product.sort_values('order_purchase_timestamp')\n",
    "poi_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_split_time = int((1 - (config.valid_size + config.test_size)) * len(poi_product))\n",
    "config.valid_split_time = int((1 - config.test_size) * len(poi_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e874f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(data, train_split_time, valid_split_time):\n",
    "    \n",
    "    train = data.iloc[:train_split_time]\n",
    "    valid = data.iloc[train_split_time:valid_split_time]\n",
    "    test = data.iloc[valid_split_time:]\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "# Split the dataset\n",
    "train, valid, test= train_val_split(poi_product,\n",
    "                               train_split_time=config.train_split_time,\n",
    "                               valid_split_time=config.valid_split_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc3fe168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataPreprocessing:\n",
    "#     def __init__(self, window_size, batch_size, buffer_size, stateful):\n",
    "#         self.scaler = StandardScaler()\n",
    "#         self.window_size = window_size\n",
    "#         self.batch_size = batch_size\n",
    "#         self.buffer_size = buffer_size\n",
    "#         self.stateful = stateful\n",
    "# #         scaled_data = scaler.fit_transform(data[['sales', 'price']])\n",
    "\n",
    "#     def fit(self, data):\n",
    "#         self.scaler.fit(data[['sales', 'price']])\n",
    "        \n",
    "#     def rescale(self, data):\n",
    "#         data = data.copy()\n",
    "#         scaled_data = self.scaler.transform(data[['sales', 'price']])\n",
    "#         data['scaled_sales'] = scaled_data[:,0]\n",
    "#         data['scaled_price'] = scaled_data[:,1]\n",
    "#         return data\n",
    "    \n",
    "#     def create_windowed_dataset(self, data, with_label=True, rescale=True):\n",
    "#         if rescale:\n",
    "#             data = self.rescale(data)\n",
    "        \n",
    "#         data = data[['scaled_sales', 'scaled_price', 'sales']].values\n",
    "#         ds = tf.data.Dataset.from_tensor_slices(data)\n",
    "#         ds = ds.window(self.window_size + 1, shift=1, drop_remainder=True)\n",
    "#         ds = ds.flat_map(lambda w: w.batch(self.window_size + 1))\n",
    "\n",
    "#         if not self.stateful:\n",
    "#             ds = ds.shuffle(self.buffer_size)\n",
    "\n",
    "#         if with_label:\n",
    "#             ds = ds.map(lambda w: ((w[:-1, :2], w[-1:, 1]), w[-1:, 2]))\n",
    "#         else:\n",
    "#             ds = ds.map(lambda w: (w[:-1, :2], w[-1:, 1]))\n",
    "\n",
    "#         ds = ds.batch(self.batch_size, drop_remainder=self.stateful)\n",
    "#         if not with_label:\n",
    "#             ds = ds.prefetch(1)\n",
    "\n",
    "#         return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873ef41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/demand_forecasting/DataPreprocessing.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(DataPreprocessing, \"../model/demand_forecasting/DataPreprocessing.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ef2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataPreprocessing = joblib.load(\"../model/demand_forecasting/DataPreprocessing.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3458bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils.DataPreprocessing"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "953ebdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DataPreprocessing, ModelPipeline\n",
    "    \n",
    "data_pipeline = DataPreprocessing(\n",
    "    window_size = config.window_size,\n",
    "    batch_size = config.batch_size,\n",
    "    buffer_size = config.buffer_size,\n",
    "    stateful = config.stateful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7597bffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/demand_forecasting/data_pipeline.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(data_pipeline, \"../model/demand_forecasting/data_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16422904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation to the  dataset\n",
    "data_pipeline.fit(train)\n",
    "train_set = data_pipeline.create_windowed_dataset(train)\n",
    "valid_set = data_pipeline.create_windowed_dataset(valid)\n",
    "test_set = data_pipeline.create_windowed_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a31eca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(8, 30, 2), dtype=float64, numpy=\n",
      "array([[[-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079]],\n",
      "\n",
      "       [[ 0.40413248,  0.8917591 ],\n",
      "        [ 0.43400189,  0.91985036],\n",
      "        [ 0.43400189,  0.81370959],\n",
      "        [ 0.46387131,  0.76936852],\n",
      "        [ 0.47382778,  0.91487475],\n",
      "        [ 0.51365367,  0.89347016],\n",
      "        [ 0.53356661,  0.97538077],\n",
      "        [ 0.54352308,  0.95578994],\n",
      "        [ 0.5733925 ,  0.94542723],\n",
      "        [ 0.5733925 ,  0.91527588],\n",
      "        [ 0.58334897,  0.90086969],\n",
      "        [ 0.59330544,  0.93240868],\n",
      "        [ 0.5733925 ,  0.9170266 ],\n",
      "        [ 0.5733925 ,  0.968754  ],\n",
      "        [ 0.60326191,  1.05325865],\n",
      "        [ 0.58334897,  0.98473552],\n",
      "        [ 0.5733925 ,  0.81667772],\n",
      "        [ 0.60326191,  0.82110989],\n",
      "        [ 0.62317486,  1.22059145],\n",
      "        [ 0.63313133,  1.20754335],\n",
      "        [ 0.63313133,  1.2054996 ],\n",
      "        [ 0.6430878 ,  1.19009524],\n",
      "        [ 0.63313133,  1.19905889],\n",
      "        [ 0.6430878 ,  1.19308028],\n",
      "        [ 0.6430878 ,  1.22746296],\n",
      "        [ 0.6430878 ,  1.18682888],\n",
      "        [ 0.66300074,  1.33513556],\n",
      "        [ 0.63313133,  1.29497442],\n",
      "        [ 0.66300074,  1.31937877],\n",
      "        [ 0.65304427,  0.82603587]],\n",
      "\n",
      "       [[ 0.21495951,  0.96406036],\n",
      "        [ 0.26474187,  0.86488718],\n",
      "        [ 0.23487245,  0.80382878],\n",
      "        [ 0.2547854 ,  0.72633265],\n",
      "        [ 0.27469834,  0.99738848],\n",
      "        [ 0.26474187,  0.80609847],\n",
      "        [ 0.23487245,  0.85713133],\n",
      "        [ 0.2547854 ,  0.8632734 ],\n",
      "        [ 0.24482893,  0.84721698],\n",
      "        [ 0.26474187,  0.81042716],\n",
      "        [ 0.29461129,  0.82695884],\n",
      "        [ 0.30456776,  0.89416317],\n",
      "        [ 0.30456776,  0.83608547],\n",
      "        [ 0.35435012,  0.84106967],\n",
      "        [ 0.37426306,  1.12622919],\n",
      "        [ 0.38421953,  0.87829433],\n",
      "        [ 0.394176  ,  0.86382575],\n",
      "        [ 0.37426306,  0.85246072],\n",
      "        [ 0.38421953,  0.87121823],\n",
      "        [ 0.394176  ,  0.89966142],\n",
      "        [ 0.38421953,  0.89750295],\n",
      "        [ 0.40413248,  0.8917591 ],\n",
      "        [ 0.43400189,  0.91985036],\n",
      "        [ 0.43400189,  0.81370959],\n",
      "        [ 0.46387131,  0.76936852],\n",
      "        [ 0.47382778,  0.91487475],\n",
      "        [ 0.51365367,  0.89347016],\n",
      "        [ 0.53356661,  0.97538077],\n",
      "        [ 0.54352308,  0.95578994],\n",
      "        [ 0.5733925 ,  0.94542723]],\n",
      "\n",
      "       [[-0.18329936,  0.70917027],\n",
      "        [-0.18329936,  0.7034561 ],\n",
      "        [-0.18329936,  0.5668875 ],\n",
      "        [-0.15342995,  0.79941788],\n",
      "        [-0.14347348,  0.8456196 ],\n",
      "        [-0.12356053,  0.84731794],\n",
      "        [-0.133517  ,  0.79827385],\n",
      "        [-0.12356053,  0.77409912],\n",
      "        [-0.133517  ,  0.80035765],\n",
      "        [-0.11360406,  0.7691154 ],\n",
      "        [-0.11360406,  0.76236724],\n",
      "        [-0.11360406,  0.76236724],\n",
      "        [-0.11360406,  0.76441602],\n",
      "        [-0.10364759,  0.73947875],\n",
      "        [-0.10364759,  0.73947875],\n",
      "        [-0.08373464,  0.71111438],\n",
      "        [-0.08373464,  0.70961558],\n",
      "        [-0.05386523,  0.76600925],\n",
      "        [-0.04390876,  0.76186245],\n",
      "        [ 0.01583007,  0.7396032 ],\n",
      "        [ 0.0058736 ,  1.14271534],\n",
      "        [ 0.04569949,  1.074621  ],\n",
      "        [ 0.05565596,  1.0404343 ],\n",
      "        [ 0.07556891,  1.00925226],\n",
      "        [ 0.07556891,  0.92884095],\n",
      "        [ 0.12535126,  0.86210819],\n",
      "        [ 0.15522068,  0.97932964],\n",
      "        [ 0.19504657,  0.9616603 ],\n",
      "        [ 0.21495951,  0.96406036],\n",
      "        [ 0.26474187,  0.86488718]],\n",
      "\n",
      "       [[-0.18329936,  0.7034561 ],\n",
      "        [-0.18329936,  0.5668875 ],\n",
      "        [-0.15342995,  0.79941788],\n",
      "        [-0.14347348,  0.8456196 ],\n",
      "        [-0.12356053,  0.84731794],\n",
      "        [-0.133517  ,  0.79827385],\n",
      "        [-0.12356053,  0.77409912],\n",
      "        [-0.133517  ,  0.80035765],\n",
      "        [-0.11360406,  0.7691154 ],\n",
      "        [-0.11360406,  0.76236724],\n",
      "        [-0.11360406,  0.76236724],\n",
      "        [-0.11360406,  0.76441602],\n",
      "        [-0.10364759,  0.73947875],\n",
      "        [-0.10364759,  0.73947875],\n",
      "        [-0.08373464,  0.71111438],\n",
      "        [-0.08373464,  0.70961558],\n",
      "        [-0.05386523,  0.76600925],\n",
      "        [-0.04390876,  0.76186245],\n",
      "        [ 0.01583007,  0.7396032 ],\n",
      "        [ 0.0058736 ,  1.14271534],\n",
      "        [ 0.04569949,  1.074621  ],\n",
      "        [ 0.05565596,  1.0404343 ],\n",
      "        [ 0.07556891,  1.00925226],\n",
      "        [ 0.07556891,  0.92884095],\n",
      "        [ 0.12535126,  0.86210819],\n",
      "        [ 0.15522068,  0.97932964],\n",
      "        [ 0.19504657,  0.9616603 ],\n",
      "        [ 0.21495951,  0.96406036],\n",
      "        [ 0.26474187,  0.86488718],\n",
      "        [ 0.23487245,  0.80382878]],\n",
      "\n",
      "       [[ 0.60326191,  0.82110989],\n",
      "        [ 0.62317486,  1.22059145],\n",
      "        [ 0.63313133,  1.20754335],\n",
      "        [ 0.63313133,  1.2054996 ],\n",
      "        [ 0.6430878 ,  1.19009524],\n",
      "        [ 0.63313133,  1.19905889],\n",
      "        [ 0.6430878 ,  1.19308028],\n",
      "        [ 0.6430878 ,  1.22746296],\n",
      "        [ 0.6430878 ,  1.18682888],\n",
      "        [ 0.66300074,  1.33513556],\n",
      "        [ 0.63313133,  1.29497442],\n",
      "        [ 0.66300074,  1.31937877],\n",
      "        [ 0.65304427,  0.82603587],\n",
      "        [ 0.66300074,  0.84195363],\n",
      "        [ 0.67295722,  0.79424756],\n",
      "        [ 0.7127831 ,  0.78937818],\n",
      "        [ 0.70282663,  0.8009182 ],\n",
      "        [ 0.76256546,  0.80467808],\n",
      "        [ 0.75260899,  0.8003573 ],\n",
      "        [ 0.80239135,  0.75451263],\n",
      "        [ 0.80239135,  0.7287615 ],\n",
      "        [ 0.81234782,  0.71024148],\n",
      "        [ 0.87208665,  0.89210517],\n",
      "        [ 0.90195607,  0.73687602],\n",
      "        [ 0.90195607,  0.67458867],\n",
      "        [ 0.8919996 ,  0.69953084],\n",
      "        [ 0.8919996 ,  0.68139788],\n",
      "        [ 0.93182549,  0.68077562],\n",
      "        [ 0.91191254,  0.67246156],\n",
      "        [ 0.98160784,  0.64031498]],\n",
      "\n",
      "       [[ 1.13095492,  0.5973731 ],\n",
      "        [ 1.16082434,  0.56913645],\n",
      "        [ 1.15086787,  0.54667805],\n",
      "        [ 1.17078081,  0.53206874],\n",
      "        [ 1.17078081,  0.53146537],\n",
      "        [ 1.17078081,  0.52766699],\n",
      "        [ 1.15086787,  0.53924251],\n",
      "        [ 1.13095492,  0.530789  ],\n",
      "        [ 1.13095492,  0.53140101],\n",
      "        [ 1.16082434,  0.51225821],\n",
      "        [ 1.19069375,  0.65365806],\n",
      "        [ 1.19069375,  0.67250171],\n",
      "        [ 1.18073728,  0.66760316],\n",
      "        [ 1.23051964,  0.7717961 ],\n",
      "        [ 1.22056317,  0.74893518],\n",
      "        [ 1.24047611,  0.776533  ],\n",
      "        [ 1.25043258,  0.76045713],\n",
      "        [ 1.280302  ,  0.75404575],\n",
      "        [ 1.27034553,  0.75800311],\n",
      "        [ 1.280302  ,  0.7423203 ],\n",
      "        [ 1.32012789,  0.80312658],\n",
      "        [ 1.32012789,  1.00928156],\n",
      "        [ 1.3499973 ,  0.75686008],\n",
      "        [ 1.3499973 ,  0.75150967],\n",
      "        [ 1.32012789,  0.79417047],\n",
      "        [ 1.34004083,  0.7701997 ],\n",
      "        [ 1.34004083,  0.75755982],\n",
      "        [ 1.35995378,  0.74402672],\n",
      "        [ 1.37986672,  0.71276639],\n",
      "        [ 1.42964908,  0.7637864 ]],\n",
      "\n",
      "       [[ 0.26474187,  0.81042716],\n",
      "        [ 0.29461129,  0.82695884],\n",
      "        [ 0.30456776,  0.89416317],\n",
      "        [ 0.30456776,  0.83608547],\n",
      "        [ 0.35435012,  0.84106967],\n",
      "        [ 0.37426306,  1.12622919],\n",
      "        [ 0.38421953,  0.87829433],\n",
      "        [ 0.394176  ,  0.86382575],\n",
      "        [ 0.37426306,  0.85246072],\n",
      "        [ 0.38421953,  0.87121823],\n",
      "        [ 0.394176  ,  0.89966142],\n",
      "        [ 0.38421953,  0.89750295],\n",
      "        [ 0.40413248,  0.8917591 ],\n",
      "        [ 0.43400189,  0.91985036],\n",
      "        [ 0.43400189,  0.81370959],\n",
      "        [ 0.46387131,  0.76936852],\n",
      "        [ 0.47382778,  0.91487475],\n",
      "        [ 0.51365367,  0.89347016],\n",
      "        [ 0.53356661,  0.97538077],\n",
      "        [ 0.54352308,  0.95578994],\n",
      "        [ 0.5733925 ,  0.94542723],\n",
      "        [ 0.5733925 ,  0.91527588],\n",
      "        [ 0.58334897,  0.90086969],\n",
      "        [ 0.59330544,  0.93240868],\n",
      "        [ 0.5733925 ,  0.9170266 ],\n",
      "        [ 0.5733925 ,  0.968754  ],\n",
      "        [ 0.60326191,  1.05325865],\n",
      "        [ 0.58334897,  0.98473552],\n",
      "        [ 0.5733925 ,  0.81667772],\n",
      "        [ 0.60326191,  0.82110989]]])>, <tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
      "array([[-1.38934079],\n",
      "       [ 0.84195363],\n",
      "       [ 0.91527588],\n",
      "       [ 0.80382878],\n",
      "       [ 0.72633265],\n",
      "       [ 0.75286948],\n",
      "       [ 0.7473153 ],\n",
      "       [ 1.22059145]])>), <tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
      "array([[ 11.],\n",
      "       [197.],\n",
      "       [188.],\n",
      "       [154.],\n",
      "       [156.],\n",
      "       [232.],\n",
      "       [273.],\n",
      "       [193.]])>)\n",
      "((<tf.Tensor: shape=(8, 30, 2), dtype=float64, numpy=\n",
      "array([[[ 0.62317486,  1.22059145],\n",
      "        [ 0.63313133,  1.20754335],\n",
      "        [ 0.63313133,  1.2054996 ],\n",
      "        [ 0.6430878 ,  1.19009524],\n",
      "        [ 0.63313133,  1.19905889],\n",
      "        [ 0.6430878 ,  1.19308028],\n",
      "        [ 0.6430878 ,  1.22746296],\n",
      "        [ 0.6430878 ,  1.18682888],\n",
      "        [ 0.66300074,  1.33513556],\n",
      "        [ 0.63313133,  1.29497442],\n",
      "        [ 0.66300074,  1.31937877],\n",
      "        [ 0.65304427,  0.82603587],\n",
      "        [ 0.66300074,  0.84195363],\n",
      "        [ 0.67295722,  0.79424756],\n",
      "        [ 0.7127831 ,  0.78937818],\n",
      "        [ 0.70282663,  0.8009182 ],\n",
      "        [ 0.76256546,  0.80467808],\n",
      "        [ 0.75260899,  0.8003573 ],\n",
      "        [ 0.80239135,  0.75451263],\n",
      "        [ 0.80239135,  0.7287615 ],\n",
      "        [ 0.81234782,  0.71024148],\n",
      "        [ 0.87208665,  0.89210517],\n",
      "        [ 0.90195607,  0.73687602],\n",
      "        [ 0.90195607,  0.67458867],\n",
      "        [ 0.8919996 ,  0.69953084],\n",
      "        [ 0.8919996 ,  0.68139788],\n",
      "        [ 0.93182549,  0.68077562],\n",
      "        [ 0.91191254,  0.67246156],\n",
      "        [ 0.98160784,  0.64031498],\n",
      "        [ 1.01147726,  0.75286948]],\n",
      "\n",
      "       [[-1.0893383 , -1.45175632],\n",
      "        [-1.04951242,  0.81061328],\n",
      "        [-1.07938183, -1.4672474 ],\n",
      "        [-1.06942536, -1.51079372],\n",
      "        [-1.06942536, -1.52404396],\n",
      "        [-1.05946889, -1.53166396],\n",
      "        [-0.99973006, -1.28508114],\n",
      "        [-0.98977358, -1.1630629 ],\n",
      "        [-0.97981711, -1.20386758],\n",
      "        [-0.95990417, -1.25766031],\n",
      "        [-0.96986064, -1.24228237],\n",
      "        [-0.9499477 , -1.31580921],\n",
      "        [-0.92007828, -0.82063042],\n",
      "        [-0.92007828, -1.22322057],\n",
      "        [-0.90016534, -1.09937071],\n",
      "        [-0.89020887,  1.70158896],\n",
      "        [-0.91012181, -1.17060869],\n",
      "        [-0.92007828, -1.15649513],\n",
      "        [-0.88025239, -1.21675348],\n",
      "        [-0.85038298, -0.95201715],\n",
      "        [-0.85038298, -0.91071261],\n",
      "        [-0.83047003, -0.87443531],\n",
      "        [-0.83047003, -0.87443531],\n",
      "        [-0.82051356, -0.91209586],\n",
      "        [-0.83047003, -0.87118675],\n",
      "        [-0.79064415, -0.97343091],\n",
      "        [-0.80060062, -0.93589829],\n",
      "        [-0.78068767, -0.97551628],\n",
      "        [-0.74086179, -0.92594954],\n",
      "        [-0.7707312 , -0.96804103]],\n",
      "\n",
      "       [[-0.73090532, -0.72130149],\n",
      "        [-0.7010359 , -0.79597891],\n",
      "        [-0.69107943, -0.79737329],\n",
      "        [-0.68112296, -0.72454911],\n",
      "        [-0.65125354,  1.02825752],\n",
      "        [-0.6313406 ,  0.95670819],\n",
      "        [-0.59151471,  0.90107572],\n",
      "        [-0.59151471,  0.8161691 ],\n",
      "        [-0.59151471,  0.76032586],\n",
      "        [-0.58155824,  0.80969698],\n",
      "        [-0.58155824,  0.80969698],\n",
      "        [-0.57160177,  0.86961346],\n",
      "        [-0.54173235,  0.91634807],\n",
      "        [-0.57160177,  0.87332479],\n",
      "        [-0.56164529,  0.90105501],\n",
      "        [-0.56164529,  0.83680924],\n",
      "        [-0.54173235,  0.913902  ],\n",
      "        [-0.48199352,  0.75591381],\n",
      "        [-0.48199352,  0.7813386 ],\n",
      "        [-0.42225469,  1.35538493],\n",
      "        [-0.43221116,  0.63865028],\n",
      "        [-0.44216763,  0.8647597 ],\n",
      "        [-0.44216763,  0.69855805],\n",
      "        [-0.42225469,  0.56279186],\n",
      "        [-0.3824288 ,  0.56358808],\n",
      "        [-0.41229822,  0.50973131],\n",
      "        [-0.3824288 ,  0.56059021],\n",
      "        [-0.33264644,  0.41108034],\n",
      "        [-0.36251586,  0.51273104],\n",
      "        [-0.36251586,  0.55649913]],\n",
      "\n",
      "       [[ 0.87208665,  0.89210517],\n",
      "        [ 0.90195607,  0.73687602],\n",
      "        [ 0.90195607,  0.67458867],\n",
      "        [ 0.8919996 ,  0.69953084],\n",
      "        [ 0.8919996 ,  0.68139788],\n",
      "        [ 0.93182549,  0.68077562],\n",
      "        [ 0.91191254,  0.67246156],\n",
      "        [ 0.98160784,  0.64031498],\n",
      "        [ 1.01147726,  0.75286948],\n",
      "        [ 0.98160784,  0.65868682],\n",
      "        [ 0.98160784,  0.6361562 ],\n",
      "        [ 0.98160784,  0.64379372],\n",
      "        [ 0.98160784,  0.63672845],\n",
      "        [ 1.01147726,  0.57930395],\n",
      "        [ 1.02143373,  0.56085794],\n",
      "        [ 0.98160784,  0.63407281],\n",
      "        [ 1.02143373,  0.6219137 ],\n",
      "        [ 1.01147726,  0.52656153],\n",
      "        [ 1.05130315,  0.52047274],\n",
      "        [ 1.01147726,  0.50291539],\n",
      "        [ 1.01147726,  0.496794  ],\n",
      "        [ 1.02143373,  0.51562725],\n",
      "        [ 1.00152079,  0.48826494],\n",
      "        [ 0.99156432,  0.49058785],\n",
      "        [ 1.02143373,  0.51219907],\n",
      "        [ 1.02143373,  0.5065539 ],\n",
      "        [ 1.01147726,  0.52069367],\n",
      "        [ 1.02143373,  0.64560354],\n",
      "        [ 1.01147726,  0.51779718],\n",
      "        [ 1.09112903,  0.53615853]],\n",
      "\n",
      "       [[-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.18890302, -1.38934079],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.17894655, -1.4462816 ],\n",
      "        [-1.15903361, -1.23100444],\n",
      "        [-1.14907713, -1.19568617],\n",
      "        [-1.14907713, -1.19568617],\n",
      "        [-1.13912066, -1.28858964],\n",
      "        [-1.13912066, -1.28858964],\n",
      "        [-1.11920772, -1.42973168]],\n",
      "\n",
      "       [[ 1.13095492,  0.55399164],\n",
      "        [ 1.12099845,  0.54895977],\n",
      "        [ 1.13095492,  0.56372134],\n",
      "        [ 1.13095492,  0.5643321 ],\n",
      "        [ 1.17078081,  0.63110693],\n",
      "        [ 1.14091139,  0.60374793],\n",
      "        [ 1.16082434,  0.60682621],\n",
      "        [ 1.13095492,  0.61777549],\n",
      "        [ 1.14091139,  0.62173224],\n",
      "        [ 1.12099845,  0.59367481],\n",
      "        [ 1.13095492,  0.5973731 ],\n",
      "        [ 1.16082434,  0.56913645],\n",
      "        [ 1.15086787,  0.54667805],\n",
      "        [ 1.17078081,  0.53206874],\n",
      "        [ 1.17078081,  0.53146537],\n",
      "        [ 1.17078081,  0.52766699],\n",
      "        [ 1.15086787,  0.53924251],\n",
      "        [ 1.13095492,  0.530789  ],\n",
      "        [ 1.13095492,  0.53140101],\n",
      "        [ 1.16082434,  0.51225821],\n",
      "        [ 1.19069375,  0.65365806],\n",
      "        [ 1.19069375,  0.67250171],\n",
      "        [ 1.18073728,  0.66760316],\n",
      "        [ 1.23051964,  0.7717961 ],\n",
      "        [ 1.22056317,  0.74893518],\n",
      "        [ 1.24047611,  0.776533  ],\n",
      "        [ 1.25043258,  0.76045713],\n",
      "        [ 1.280302  ,  0.75404575],\n",
      "        [ 1.27034553,  0.75800311],\n",
      "        [ 1.280302  ,  0.7423203 ]],\n",
      "\n",
      "       [[-0.7707312 , -0.96804103],\n",
      "        [-0.78068767, -1.01809415],\n",
      "        [-0.7707312 , -1.04943377],\n",
      "        [-0.7707312 , -1.05800143],\n",
      "        [-0.7707312 , -1.07697678],\n",
      "        [-0.76077473, -0.99921927],\n",
      "        [-0.75081826, -1.01757223],\n",
      "        [-0.73090532, -0.41921921],\n",
      "        [-0.73090532, -0.72130149],\n",
      "        [-0.7010359 , -0.79597891],\n",
      "        [-0.69107943, -0.79737329],\n",
      "        [-0.68112296, -0.72454911],\n",
      "        [-0.65125354,  1.02825752],\n",
      "        [-0.6313406 ,  0.95670819],\n",
      "        [-0.59151471,  0.90107572],\n",
      "        [-0.59151471,  0.8161691 ],\n",
      "        [-0.59151471,  0.76032586],\n",
      "        [-0.58155824,  0.80969698],\n",
      "        [-0.58155824,  0.80969698],\n",
      "        [-0.57160177,  0.86961346],\n",
      "        [-0.54173235,  0.91634807],\n",
      "        [-0.57160177,  0.87332479],\n",
      "        [-0.56164529,  0.90105501],\n",
      "        [-0.56164529,  0.83680924],\n",
      "        [-0.54173235,  0.913902  ],\n",
      "        [-0.48199352,  0.75591381],\n",
      "        [-0.48199352,  0.7813386 ],\n",
      "        [-0.42225469,  1.35538493],\n",
      "        [-0.43221116,  0.63865028],\n",
      "        [-0.44216763,  0.8647597 ]],\n",
      "\n",
      "       [[-0.58155824,  0.80969698],\n",
      "        [-0.58155824,  0.80969698],\n",
      "        [-0.57160177,  0.86961346],\n",
      "        [-0.54173235,  0.91634807],\n",
      "        [-0.57160177,  0.87332479],\n",
      "        [-0.56164529,  0.90105501],\n",
      "        [-0.56164529,  0.83680924],\n",
      "        [-0.54173235,  0.913902  ],\n",
      "        [-0.48199352,  0.75591381],\n",
      "        [-0.48199352,  0.7813386 ],\n",
      "        [-0.42225469,  1.35538493],\n",
      "        [-0.43221116,  0.63865028],\n",
      "        [-0.44216763,  0.8647597 ],\n",
      "        [-0.44216763,  0.69855805],\n",
      "        [-0.42225469,  0.56279186],\n",
      "        [-0.3824288 ,  0.56358808],\n",
      "        [-0.41229822,  0.50973131],\n",
      "        [-0.3824288 ,  0.56059021],\n",
      "        [-0.33264644,  0.41108034],\n",
      "        [-0.36251586,  0.51273104],\n",
      "        [-0.36251586,  0.55649913],\n",
      "        [-0.36251586,  0.55649913],\n",
      "        [-0.33264644,  0.52217161],\n",
      "        [-0.32268997,  1.47532774],\n",
      "        [-0.34260291,  0.55237533],\n",
      "        [-0.3127335 ,  0.73409143],\n",
      "        [-0.3127335 ,  0.7365541 ],\n",
      "        [-0.29282055,  0.70542179],\n",
      "        [-0.28286408,  0.84760021],\n",
      "        [-0.25299467,  1.00137808]]])>, <tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
      "array([[ 0.65868682],\n",
      "       [-1.01809415],\n",
      "       [ 0.55649913],\n",
      "       [ 0.47529133],\n",
      "       [-1.30781252],\n",
      "       [ 0.80312658],\n",
      "       [ 0.69855805],\n",
      "       [ 1.02552042]])>), <tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
      "array([[229.],\n",
      "       [ 52.],\n",
      "       [ 94.],\n",
      "       [238.],\n",
      "       [ 18.],\n",
      "       [263.],\n",
      "       [ 86.],\n",
      "       [107.]])>)\n"
     ]
    }
   ],
   "source": [
    "show_sample(train_set, n_sample=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4b564f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.rnn_unit = 256\n",
    "config.rnn_layer = 2\n",
    "config.fc1_unit = 128\n",
    "config.fc2_unit = 64\n",
    "config.dropout_rate = 0.1\n",
    "\n",
    "config.batch_normalization = False\n",
    "config.use_bias = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e68e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input, GRU, LSTM, Concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(rnn_unit, fc1_unit, fc2_unit, dropout_rate=0, rnn_layer=0, stateful=False, batch_normalization=False):\n",
    "    if stateful:\n",
    "        history_input = Input(batch_shape=(config.batch_size, config.window_size, 2), name='history_input')\n",
    "    else:\n",
    "        history_input = Input(shape=(config.window_size, 2))\n",
    "    price_input = Input(shape=(1), name='price_input')\n",
    "    \n",
    "    if config.batch_normalization:\n",
    "        history_input = BatchNormalization()(history_input)\n",
    "        price_input = BatchNormalization()(price_input)\n",
    "        \n",
    "    rnn = history_input\n",
    "    for i in range(rnn_layer-1):\n",
    "        rnn = LSTM(rnn_unit, use_bias=config.use_bias, return_sequences=True, dropout=dropout_rate, stateful=stateful)(rnn)\n",
    "    if rnn_layer > 0:\n",
    "        rnn = LSTM(rnn_unit, use_bias=config.use_bias, dropout=dropout_rate, stateful=stateful)(rnn)\n",
    "    else:\n",
    "        rnn = Flatten()(rnn)\n",
    "        \n",
    "    \n",
    "    concat_ = Concatenate()([rnn, price_input])\n",
    "    if dropout_rate > 0:\n",
    "        concat_ = Dropout(dropout_rate)(concat_)\n",
    "    fc = Dense(fc1_unit, activation='relu', use_bias=config.use_bias)(concat_)\n",
    "    \n",
    "    if dropout_rate > 0:\n",
    "        fc = Dropout(dropout_rate)(fc)\n",
    "    fc = Dense(fc2_unit, activation='relu', use_bias=config.use_bias)(fc)\n",
    "    \n",
    "    if dropout_rate > 0:\n",
    "        fc = Dropout(dropout_rate)(fc)\n",
    "    output = Dense(1, use_bias=config.use_bias, name='sales_output')(fc)\n",
    "    \n",
    "    model = Model([history_input, price_input], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dee151b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    rnn_unit=config.rnn_unit,\n",
    "    rnn_layer=config.rnn_layer,\n",
    "    fc1_unit=config.fc1_unit,\n",
    "    fc2_unit=config.fc2_unit,\n",
    "    stateful=config.stateful,\n",
    "    batch_normalization=config.batch_normalization,\n",
    "    dropout_rate=config.dropout_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2a27a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='mse',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c817454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='../model/demand_forecasting',\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d67b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "     49/Unknown - 14s 162ms/step - loss: 14620.8369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 27s 431ms/step - loss: 14620.8369 - val_loss: 6051.6914 - _timestamp: 1654088304.0000 - _runtime: 213.0000\n",
      "Epoch 2/1000\n",
      "49/49 [==============================] - 8s 167ms/step - loss: 2904.7668 - val_loss: 9031.5098 - _timestamp: 1654088324.0000 - _runtime: 233.0000\n",
      "Epoch 3/1000\n",
      "49/49 [==============================] - 8s 152ms/step - loss: 2449.0342 - val_loss: 9412.5146 - _timestamp: 1654088333.0000 - _runtime: 242.0000\n",
      "Epoch 4/1000\n",
      "49/49 [==============================] - 9s 176ms/step - loss: 4298.9346 - val_loss: 15706.3262 - _timestamp: 1654088342.0000 - _runtime: 251.0000\n",
      "Epoch 5/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 2200.0557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 22s 464ms/step - loss: 2200.0557 - val_loss: 5164.0747 - _timestamp: 1654088351.0000 - _runtime: 260.0000\n",
      "Epoch 6/1000\n",
      "49/49 [==============================] - 11s 220ms/step - loss: 1881.3016 - val_loss: 10042.6211 - _timestamp: 1654088394.0000 - _runtime: 303.0000\n",
      "Epoch 7/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 1320.4993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 16s 329ms/step - loss: 1320.4993 - val_loss: 4019.6628 - _timestamp: 1654088410.0000 - _runtime: 319.0000\n",
      "Epoch 8/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 855.9359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 20s 410ms/step - loss: 855.9359 - val_loss: 3928.1123 - _timestamp: 1654088426.0000 - _runtime: 335.0000\n",
      "Epoch 9/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 777.5227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 20s 418ms/step - loss: 777.5227 - val_loss: 3329.9141 - _timestamp: 1654088448.0000 - _runtime: 357.0000\n",
      "Epoch 10/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 644.7742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 28s 582ms/step - loss: 644.7742 - val_loss: 2177.0769 - _timestamp: 1654088469.0000 - _runtime: 378.0000\n",
      "Epoch 11/1000\n",
      "49/49 [==============================] - 11s 206ms/step - loss: 676.0961 - val_loss: 2485.0579 - _timestamp: 1654088511.0000 - _runtime: 420.0000\n",
      "Epoch 12/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 614.0915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 25s 524ms/step - loss: 614.0915 - val_loss: 1462.2343 - _timestamp: 1654088521.0000 - _runtime: 430.0000\n",
      "Epoch 13/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 640.7676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 27s 549ms/step - loss: 640.7676 - val_loss: 889.8943 - _timestamp: 1654088547.0000 - _runtime: 456.0000\n",
      "Epoch 14/1000\n",
      "49/49 [==============================] - 11s 232ms/step - loss: 546.8864 - val_loss: 1561.4294 - _timestamp: 1654088575.0000 - _runtime: 484.0000\n",
      "Epoch 15/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 557.8026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 26s 540ms/step - loss: 557.8026 - val_loss: 676.1052 - _timestamp: 1654088586.0000 - _runtime: 495.0000\n",
      "Epoch 16/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 491.5044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 24s 504ms/step - loss: 491.5044 - val_loss: 591.1827 - _timestamp: 1654088626.0000 - _runtime: 535.0000\n",
      "Epoch 17/1000\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 571.3226 - val_loss: 1097.7404 - _timestamp: 1654088649.0000 - _runtime: 558.0000\n",
      "Epoch 18/1000\n",
      "49/49 [==============================] - 8s 151ms/step - loss: 449.9681 - val_loss: 1324.3972 - _timestamp: 1654088656.0000 - _runtime: 565.0000\n",
      "Epoch 19/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 451.1951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 19s 383ms/step - loss: 451.1951 - val_loss: 512.2059 - _timestamp: 1654088664.0000 - _runtime: 573.0000\n",
      "Epoch 20/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 471.2496 - val_loss: 837.8433 - _timestamp: 1654088687.0000 - _runtime: 596.0000\n",
      "Epoch 21/1000\n",
      "49/49 [==============================] - 8s 171ms/step - loss: 496.8662 - val_loss: 3375.1006 - _timestamp: 1654088695.0000 - _runtime: 604.0000\n",
      "Epoch 22/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 531.9800 - val_loss: 1715.1858 - _timestamp: 1654088705.0000 - _runtime: 614.0000\n",
      "Epoch 23/1000\n",
      "49/49 [==============================] - 9s 174ms/step - loss: 472.3253 - val_loss: 1185.5100 - _timestamp: 1654088714.0000 - _runtime: 623.0000\n",
      "Epoch 24/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 424.1308 - val_loss: 726.4846 - _timestamp: 1654088724.0000 - _runtime: 633.0000\n",
      "Epoch 25/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 436.0961 - val_loss: 818.0766 - _timestamp: 1654088733.0000 - _runtime: 642.0000\n",
      "Epoch 26/1000\n",
      "49/49 [==============================] - 9s 172ms/step - loss: 523.9221 - val_loss: 720.8611 - _timestamp: 1654088742.0000 - _runtime: 651.0000\n",
      "Epoch 27/1000\n",
      "49/49 [==============================] - 8s 173ms/step - loss: 499.4391 - val_loss: 2468.3271 - _timestamp: 1654088751.0000 - _runtime: 660.0000\n",
      "Epoch 28/1000\n",
      "49/49 [==============================] - 9s 194ms/step - loss: 513.7509 - val_loss: 2037.8242 - _timestamp: 1654088760.0000 - _runtime: 669.0000\n",
      "Epoch 29/1000\n",
      "49/49 [==============================] - 8s 156ms/step - loss: 418.1672 - val_loss: 2180.6533 - _timestamp: 1654088768.0000 - _runtime: 677.0000\n",
      "Epoch 30/1000\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 415.0510 - val_loss: 851.4425 - _timestamp: 1654088776.0000 - _runtime: 685.0000\n",
      "Epoch 31/1000\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 337.6057 - val_loss: 972.2106 - _timestamp: 1654088783.0000 - _runtime: 692.0000\n",
      "Epoch 32/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 451.8479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 21s 440ms/step - loss: 451.8479 - val_loss: 484.5782 - _timestamp: 1654088792.0000 - _runtime: 701.0000\n",
      "Epoch 33/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 393.3965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 25s 509ms/step - loss: 393.3965 - val_loss: 389.1769 - _timestamp: 1654088815.0000 - _runtime: 724.0000\n",
      "Epoch 34/1000\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 468.3815 - val_loss: 501.4390 - _timestamp: 1654088840.0000 - _runtime: 749.0000\n",
      "Epoch 35/1000\n",
      "49/49 [==============================] - 8s 165ms/step - loss: 599.4254 - val_loss: 2655.7368 - _timestamp: 1654088848.0000 - _runtime: 757.0000\n",
      "Epoch 36/1000\n",
      "49/49 [==============================] - 7s 151ms/step - loss: 517.5475 - val_loss: 2101.4744 - _timestamp: 1654088856.0000 - _runtime: 765.0000\n",
      "Epoch 37/1000\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 464.9200 - val_loss: 1122.2970 - _timestamp: 1654088864.0000 - _runtime: 773.0000\n",
      "Epoch 38/1000\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 352.3297 - val_loss: 907.3870 - _timestamp: 1654088871.0000 - _runtime: 780.0000\n",
      "Epoch 39/1000\n",
      "49/49 [==============================] - 8s 161ms/step - loss: 320.9933 - val_loss: 682.7946 - _timestamp: 1654088879.0000 - _runtime: 788.0000\n",
      "Epoch 40/1000\n",
      "49/49 [==============================] - 8s 162ms/step - loss: 359.5642 - val_loss: 695.3969 - _timestamp: 1654088887.0000 - _runtime: 796.0000\n",
      "Epoch 41/1000\n",
      "49/49 [==============================] - 9s 172ms/step - loss: 721.8397 - val_loss: 1652.0507 - _timestamp: 1654088896.0000 - _runtime: 805.0000\n",
      "Epoch 42/1000\n",
      "49/49 [==============================] - 26s 539ms/step - loss: 579.9625 - val_loss: 4262.2158 - _timestamp: 1654088922.0000 - _runtime: 831.0000\n",
      "Epoch 43/1000\n",
      "49/49 [==============================] - 7s 145ms/step - loss: 568.4794 - val_loss: 2915.2957 - _timestamp: 1654088929.0000 - _runtime: 838.0000\n",
      "Epoch 44/1000\n",
      "49/49 [==============================] - 7s 143ms/step - loss: 421.2144 - val_loss: 1664.9891 - _timestamp: 1654088936.0000 - _runtime: 845.0000\n",
      "Epoch 45/1000\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 461.7572 - val_loss: 1931.0610 - _timestamp: 1654088944.0000 - _runtime: 853.0000\n",
      "Epoch 46/1000\n",
      "49/49 [==============================] - 8s 158ms/step - loss: 377.3413 - val_loss: 1939.7449 - _timestamp: 1654088952.0000 - _runtime: 861.0000\n",
      "Epoch 47/1000\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 435.7390 - val_loss: 946.2618 - _timestamp: 1654088959.0000 - _runtime: 868.0000\n",
      "Epoch 48/1000\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 415.1562 - val_loss: 693.0087 - _timestamp: 1654088966.0000 - _runtime: 875.0000\n",
      "Epoch 49/1000\n",
      "49/49 [==============================] - 7s 139ms/step - loss: 514.7462 - val_loss: 1176.9669 - _timestamp: 1654088973.0000 - _runtime: 882.0000\n",
      "Epoch 50/1000\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 421.3447 - val_loss: 1002.8177 - _timestamp: 1654088980.0000 - _runtime: 889.0000\n",
      "Epoch 51/1000\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 432.0779 - val_loss: 958.9830 - _timestamp: 1654088986.0000 - _runtime: 895.0000\n",
      "Epoch 52/1000\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 546.2292 - val_loss: 1297.9967 - _timestamp: 1654088993.0000 - _runtime: 902.0000\n",
      "Epoch 53/1000\n",
      "49/49 [==============================] - 6s 132ms/step - loss: 536.3487 - val_loss: 1616.9067 - _timestamp: 1654089000.0000 - _runtime: 909.0000\n",
      "Epoch 54/1000\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 403.3487 - val_loss: 566.7119 - _timestamp: 1654089006.0000 - _runtime: 915.0000\n",
      "Epoch 55/1000\n",
      "49/49 [==============================] - 7s 135ms/step - loss: 516.0143 - val_loss: 648.0624 - _timestamp: 1654089013.0000 - _runtime: 922.0000\n",
      "Epoch 56/1000\n",
      "49/49 [==============================] - 7s 133ms/step - loss: 403.9638 - val_loss: 1320.4623 - _timestamp: 1654089020.0000 - _runtime: 929.0000\n",
      "Epoch 57/1000\n",
      "49/49 [==============================] - 8s 161ms/step - loss: 446.6919 - val_loss: 1274.2581 - _timestamp: 1654089028.0000 - _runtime: 937.0000\n",
      "Epoch 58/1000\n",
      "49/49 [==============================] - 11s 223ms/step - loss: 473.7917 - val_loss: 2010.4508 - _timestamp: 1654089038.0000 - _runtime: 947.0000\n",
      "Epoch 59/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 364.6208 - val_loss: 1211.6940 - _timestamp: 1654089049.0000 - _runtime: 958.0000\n",
      "Epoch 60/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 359.1113 - val_loss: 712.6316 - _timestamp: 1654089059.0000 - _runtime: 968.0000\n",
      "Epoch 61/1000\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 508.2123 - val_loss: 3173.0659 - _timestamp: 1654089068.0000 - _runtime: 977.0000\n",
      "Epoch 62/1000\n",
      "49/49 [==============================] - 9s 177ms/step - loss: 451.4274 - val_loss: 1996.9598 - _timestamp: 1654089078.0000 - _runtime: 987.0000\n",
      "Epoch 63/1000\n",
      "49/49 [==============================] - 11s 217ms/step - loss: 333.2072 - val_loss: 2046.9247 - _timestamp: 1654089088.0000 - _runtime: 997.0000\n",
      "Epoch 64/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 449.6402 - val_loss: 964.1652 - _timestamp: 1654089108.0000 - _runtime: 1017.0000\n",
      "Epoch 65/1000\n",
      "49/49 [==============================] - 8s 167ms/step - loss: 431.6304 - val_loss: 939.1100 - _timestamp: 1654089117.0000 - _runtime: 1026.0000\n",
      "Epoch 66/1000\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 411.8438 - val_loss: 801.5570 - _timestamp: 1654089125.0000 - _runtime: 1034.0000\n",
      "Epoch 67/1000\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 357.2274 - val_loss: 908.6068 - _timestamp: 1654089133.0000 - _runtime: 1042.0000\n",
      "Epoch 68/1000\n",
      "49/49 [==============================] - 8s 159ms/step - loss: 361.5477 - val_loss: 2039.2893 - _timestamp: 1654089144.0000 - _runtime: 1053.0000\n",
      "Epoch 69/1000\n",
      "49/49 [==============================] - 8s 172ms/step - loss: 362.5004 - val_loss: 1670.3303 - _timestamp: 1654089152.0000 - _runtime: 1061.0000\n",
      "Epoch 70/1000\n",
      "49/49 [==============================] - 12s 236ms/step - loss: 353.1927 - val_loss: 1133.4850 - _timestamp: 1654089166.0000 - _runtime: 1075.0000\n",
      "Epoch 71/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 408.8570 - val_loss: 3683.3967 - _timestamp: 1654089175.0000 - _runtime: 1084.0000\n",
      "Epoch 72/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 335.6090 - val_loss: 2607.3816 - _timestamp: 1654089185.0000 - _runtime: 1094.0000\n",
      "Epoch 73/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 386.6482 - val_loss: 1293.2084 - _timestamp: 1654089194.0000 - _runtime: 1103.0000\n",
      "Epoch 74/1000\n",
      "49/49 [==============================] - 8s 166ms/step - loss: 382.9569 - val_loss: 1699.5364 - _timestamp: 1654089202.0000 - _runtime: 1111.0000\n",
      "Epoch 75/1000\n",
      "49/49 [==============================] - 8s 169ms/step - loss: 405.2104 - val_loss: 1664.0593 - _timestamp: 1654089211.0000 - _runtime: 1120.0000\n",
      "Epoch 76/1000\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 479.3683 - val_loss: 2585.9377 - _timestamp: 1654089220.0000 - _runtime: 1129.0000\n",
      "Epoch 77/1000\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 421.9864 - val_loss: 2389.3350 - _timestamp: 1654089228.0000 - _runtime: 1137.0000\n",
      "Epoch 78/1000\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 381.3461 - val_loss: 1619.8168 - _timestamp: 1654089237.0000 - _runtime: 1146.0000\n",
      "Epoch 79/1000\n",
      "49/49 [==============================] - 11s 219ms/step - loss: 494.8486 - val_loss: 980.2213 - _timestamp: 1654089249.0000 - _runtime: 1158.0000\n",
      "Epoch 80/1000\n",
      "49/49 [==============================] - 9s 186ms/step - loss: 401.7936 - val_loss: 1396.5988 - _timestamp: 1654089268.0000 - _runtime: 1177.0000\n",
      "Epoch 81/1000\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 427.0341 - val_loss: 723.1143 - _timestamp: 1654089275.0000 - _runtime: 1184.0000\n",
      "Epoch 82/1000\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 379.8370 - val_loss: 1090.8677 - _timestamp: 1654089282.0000 - _runtime: 1191.0000\n",
      "Epoch 83/1000\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 417.1083 - val_loss: 1924.3568 - _timestamp: 1654089291.0000 - _runtime: 1200.0000\n",
      "Epoch 84/1000\n",
      "49/49 [==============================] - 8s 171ms/step - loss: 500.0355 - val_loss: 952.8136 - _timestamp: 1654089299.0000 - _runtime: 1208.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "49/49 [==============================] - 9s 183ms/step - loss: 378.0971 - val_loss: 1645.4600 - _timestamp: 1654089310.0000 - _runtime: 1219.0000\n",
      "Epoch 86/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 329.6339 - val_loss: 1231.8997 - _timestamp: 1654089320.0000 - _runtime: 1229.0000\n",
      "Epoch 87/1000\n",
      "49/49 [==============================] - 12s 236ms/step - loss: 286.7221 - val_loss: 846.2460 - _timestamp: 1654089331.0000 - _runtime: 1240.0000\n",
      "Epoch 88/1000\n",
      "49/49 [==============================] - 11s 232ms/step - loss: 418.6747 - val_loss: 983.7746 - _timestamp: 1654089343.0000 - _runtime: 1252.0000\n",
      "Epoch 89/1000\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 381.2893 - val_loss: 1108.6313 - _timestamp: 1654089356.0000 - _runtime: 1265.0000\n",
      "Epoch 90/1000\n",
      "49/49 [==============================] - 14s 277ms/step - loss: 389.4206 - val_loss: 839.2575 - _timestamp: 1654089370.0000 - _runtime: 1279.0000\n",
      "Epoch 91/1000\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 372.5091 - val_loss: 905.0812 - _timestamp: 1654089380.0000 - _runtime: 1289.0000\n",
      "Epoch 92/1000\n",
      "49/49 [==============================] - 12s 252ms/step - loss: 377.0290 - val_loss: 797.6282 - _timestamp: 1654089392.0000 - _runtime: 1301.0000\n",
      "Epoch 93/1000\n",
      "49/49 [==============================] - 13s 255ms/step - loss: 300.9532 - val_loss: 904.9528 - _timestamp: 1654089405.0000 - _runtime: 1314.0000\n",
      "Epoch 94/1000\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 371.2798 - val_loss: 548.1134 - _timestamp: 1654089418.0000 - _runtime: 1327.0000\n",
      "Epoch 95/1000\n",
      "49/49 [==============================] - 13s 262ms/step - loss: 389.6820 - val_loss: 1811.0386 - _timestamp: 1654089431.0000 - _runtime: 1340.0000\n",
      "Epoch 96/1000\n",
      "49/49 [==============================] - 12s 234ms/step - loss: 416.4309 - val_loss: 1996.6234 - _timestamp: 1654089443.0000 - _runtime: 1352.0000\n",
      "Epoch 97/1000\n",
      "49/49 [==============================] - 12s 251ms/step - loss: 362.6459 - val_loss: 1516.6066 - _timestamp: 1654089455.0000 - _runtime: 1364.0000\n",
      "Epoch 98/1000\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 321.7466 - val_loss: 1648.1261 - _timestamp: 1654089472.0000 - _runtime: 1381.0000\n",
      "Epoch 99/1000\n",
      "49/49 [==============================] - 12s 239ms/step - loss: 330.8190 - val_loss: 1235.3438 - _timestamp: 1654089483.0000 - _runtime: 1392.0000\n",
      "Epoch 100/1000\n",
      "49/49 [==============================] - 13s 265ms/step - loss: 363.5290 - val_loss: 796.6646 - _timestamp: 1654089496.0000 - _runtime: 1405.0000\n",
      "Epoch 101/1000\n",
      "49/49 [==============================] - 11s 230ms/step - loss: 403.2428 - val_loss: 1648.7865 - _timestamp: 1654089515.0000 - _runtime: 1424.0000\n",
      "Epoch 102/1000\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 382.9099 - val_loss: 547.9919 - _timestamp: 1654089528.0000 - _runtime: 1437.0000\n",
      "Epoch 103/1000\n",
      "49/49 [==============================] - 13s 270ms/step - loss: 345.3571 - val_loss: 562.5322 - _timestamp: 1654089541.0000 - _runtime: 1450.0000\n",
      "Epoch 104/1000\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 375.7594 - val_loss: 584.6706 - _timestamp: 1654089551.0000 - _runtime: 1460.0000\n",
      "Epoch 105/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 264.9963 - val_loss: 517.6354 - _timestamp: 1654089561.0000 - _runtime: 1470.0000\n",
      "Epoch 106/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 310.8579 - val_loss: 989.7214 - _timestamp: 1654089572.0000 - _runtime: 1481.0000\n",
      "Epoch 107/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 383.6909 - val_loss: 1370.0751 - _timestamp: 1654089582.0000 - _runtime: 1491.0000\n",
      "Epoch 108/1000\n",
      "49/49 [==============================] - 11s 221ms/step - loss: 354.3177 - val_loss: 960.4462 - _timestamp: 1654089593.0000 - _runtime: 1502.0000\n",
      "Epoch 109/1000\n",
      "49/49 [==============================] - 11s 220ms/step - loss: 361.1286 - val_loss: 1917.1066 - _timestamp: 1654089613.0000 - _runtime: 1522.0000\n",
      "Epoch 110/1000\n",
      "49/49 [==============================] - 11s 218ms/step - loss: 327.6170 - val_loss: 1021.6000 - _timestamp: 1654089634.0000 - _runtime: 1543.0000\n",
      "Epoch 111/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 368.1852 - val_loss: 1359.6013 - _timestamp: 1654089644.0000 - _runtime: 1553.0000\n",
      "Epoch 112/1000\n",
      "49/49 [==============================] - 11s 215ms/step - loss: 346.4863 - val_loss: 1024.4904 - _timestamp: 1654089655.0000 - _runtime: 1564.0000\n",
      "Epoch 113/1000\n",
      "49/49 [==============================] - 10s 211ms/step - loss: 348.5323 - val_loss: 649.2113 - _timestamp: 1654089665.0000 - _runtime: 1574.0000\n",
      "Epoch 114/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 385.3901 - val_loss: 1746.8774 - _timestamp: 1654089675.0000 - _runtime: 1584.0000\n",
      "Epoch 115/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 325.7997 - val_loss: 990.2972 - _timestamp: 1654089685.0000 - _runtime: 1594.0000\n",
      "Epoch 116/1000\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 346.2018 - val_loss: 792.7162 - _timestamp: 1654089696.0000 - _runtime: 1605.0000\n",
      "Epoch 117/1000\n",
      "49/49 [==============================] - 11s 217ms/step - loss: 311.8500 - val_loss: 721.9327 - _timestamp: 1654089707.0000 - _runtime: 1616.0000\n",
      "Epoch 118/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 363.0936 - val_loss: 599.4534 - _timestamp: 1654089727.0000 - _runtime: 1636.0000\n",
      "Epoch 119/1000\n",
      "49/49 [==============================] - 9s 173ms/step - loss: 369.0959 - val_loss: 2425.1843 - _timestamp: 1654089735.0000 - _runtime: 1644.0000\n",
      "Epoch 120/1000\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 373.0306 - val_loss: 767.1605 - _timestamp: 1654089742.0000 - _runtime: 1651.0000\n",
      "Epoch 121/1000\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 285.7558 - val_loss: 1320.7351 - _timestamp: 1654089749.0000 - _runtime: 1658.0000\n",
      "Epoch 122/1000\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 263.3360 - val_loss: 569.1043 - _timestamp: 1654089760.0000 - _runtime: 1669.0000\n",
      "Epoch 123/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 312.9894 - val_loss: 667.6078 - _timestamp: 1654089779.0000 - _runtime: 1688.0000\n",
      "Epoch 124/1000\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 378.4340 - val_loss: 3075.8113 - _timestamp: 1654089789.0000 - _runtime: 1698.0000\n",
      "Epoch 125/1000\n",
      "49/49 [==============================] - 15s 305ms/step - loss: 789.6166 - val_loss: 1872.9209 - _timestamp: 1654089804.0000 - _runtime: 1713.0000\n",
      "Epoch 126/1000\n",
      "49/49 [==============================] - 17s 335ms/step - loss: 980.4540 - val_loss: 6316.1255 - _timestamp: 1654089827.0000 - _runtime: 1736.0000\n",
      "Epoch 127/1000\n",
      "49/49 [==============================] - 16s 317ms/step - loss: 577.7890 - val_loss: 4989.7524 - _timestamp: 1654089842.0000 - _runtime: 1751.0000\n",
      "Epoch 128/1000\n",
      "49/49 [==============================] - 16s 317ms/step - loss: 519.1353 - val_loss: 2283.6438 - _timestamp: 1654089858.0000 - _runtime: 1767.0000\n",
      "Epoch 129/1000\n",
      "49/49 [==============================] - 15s 303ms/step - loss: 361.6875 - val_loss: 1668.0891 - _timestamp: 1654089873.0000 - _runtime: 1782.0000\n",
      "Epoch 130/1000\n",
      "49/49 [==============================] - 15s 315ms/step - loss: 373.1270 - val_loss: 1050.0315 - _timestamp: 1654089888.0000 - _runtime: 1797.0000\n",
      "Epoch 131/1000\n",
      "49/49 [==============================] - 15s 308ms/step - loss: 412.0014 - val_loss: 1650.1696 - _timestamp: 1654089909.0000 - _runtime: 1818.0000\n",
      "Epoch 132/1000\n",
      "49/49 [==============================] - 16s 319ms/step - loss: 409.3687 - val_loss: 1621.8744 - _timestamp: 1654089924.0000 - _runtime: 1833.0000\n",
      "Epoch 133/1000\n",
      "49/49 [==============================] - 16s 323ms/step - loss: 379.9969 - val_loss: 2468.4272 - _timestamp: 1654089940.0000 - _runtime: 1849.0000\n",
      "Epoch 134/1000\n",
      "49/49 [==============================] - 15s 313ms/step - loss: 426.0590 - val_loss: 1056.1647 - _timestamp: 1654089960.0000 - _runtime: 1869.0000\n",
      "Epoch 135/1000\n",
      "49/49 [==============================] - 15s 314ms/step - loss: 335.4735 - val_loss: 1732.0310 - _timestamp: 1654089976.0000 - _runtime: 1885.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000\n",
      "49/49 [==============================] - 14s 283ms/step - loss: 417.7411 - val_loss: 2576.4802 - _timestamp: 1654089990.0000 - _runtime: 1899.0000\n",
      "Epoch 137/1000\n",
      "49/49 [==============================] - 8s 173ms/step - loss: 379.3958 - val_loss: 1459.9252 - _timestamp: 1654089998.0000 - _runtime: 1907.0000\n",
      "Epoch 138/1000\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 332.2055 - val_loss: 1831.9457 - _timestamp: 1654090008.0000 - _runtime: 1917.0000\n",
      "Epoch 139/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 326.8945 - val_loss: 2077.3989 - _timestamp: 1654090018.0000 - _runtime: 1927.0000\n",
      "Epoch 140/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 428.3681 - val_loss: 1615.3191 - _timestamp: 1654090027.0000 - _runtime: 1936.0000\n",
      "Epoch 141/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 306.1478 - val_loss: 1193.7096 - _timestamp: 1654090037.0000 - _runtime: 1946.0000\n",
      "Epoch 142/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 433.0823 - val_loss: 1062.9368 - _timestamp: 1654090046.0000 - _runtime: 1955.0000\n",
      "Epoch 143/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 345.7915 - val_loss: 1010.3970 - _timestamp: 1654090056.0000 - _runtime: 1965.0000\n",
      "Epoch 144/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 281.7221 - val_loss: 592.8837 - _timestamp: 1654090066.0000 - _runtime: 1975.0000\n",
      "Epoch 145/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 388.3621 - val_loss: 585.7658 - _timestamp: 1654090076.0000 - _runtime: 1985.0000\n",
      "Epoch 146/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 246.5896 - val_loss: 825.3544 - _timestamp: 1654090085.0000 - _runtime: 1994.0000\n",
      "Epoch 147/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 260.6513 - val_loss: 691.9000 - _timestamp: 1654090094.0000 - _runtime: 2003.0000\n",
      "Epoch 148/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 303.9366 - val_loss: 683.2280 - _timestamp: 1654090104.0000 - _runtime: 2013.0000\n",
      "Epoch 149/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 309.3317 - val_loss: 1259.4425 - _timestamp: 1654090113.0000 - _runtime: 2022.0000\n",
      "Epoch 150/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 410.4193 - val_loss: 2274.7458 - _timestamp: 1654090123.0000 - _runtime: 2032.0000\n",
      "Epoch 151/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 326.0468 - val_loss: 906.2322 - _timestamp: 1654090134.0000 - _runtime: 2043.0000\n",
      "Epoch 152/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 351.6315 - val_loss: 989.9919 - _timestamp: 1654090144.0000 - _runtime: 2053.0000\n",
      "Epoch 153/1000\n",
      "49/49 [==============================] - 9s 194ms/step - loss: 325.9554 - val_loss: 1181.6324 - _timestamp: 1654090154.0000 - _runtime: 2063.0000\n",
      "Epoch 154/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 306.5953 - val_loss: 1433.5582 - _timestamp: 1654090164.0000 - _runtime: 2073.0000\n",
      "Epoch 155/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 337.4271 - val_loss: 1328.1858 - _timestamp: 1654090174.0000 - _runtime: 2083.0000\n",
      "Epoch 156/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 403.4833 - val_loss: 1530.9987 - _timestamp: 1654090183.0000 - _runtime: 2092.0000\n",
      "Epoch 157/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 381.9525 - val_loss: 708.3731 - _timestamp: 1654090193.0000 - _runtime: 2102.0000\n",
      "Epoch 158/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 362.7080 - val_loss: 493.7298 - _timestamp: 1654090202.0000 - _runtime: 2111.0000\n",
      "Epoch 159/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 321.0083 - val_loss: 986.9304 - _timestamp: 1654090212.0000 - _runtime: 2121.0000\n",
      "Epoch 160/1000\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 322.4247 - val_loss: 785.4346 - _timestamp: 1654090221.0000 - _runtime: 2130.0000\n",
      "Epoch 161/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 346.2425 - val_loss: 2353.7778 - _timestamp: 1654090231.0000 - _runtime: 2140.0000\n",
      "Epoch 162/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 353.1401 - val_loss: 472.3810 - _timestamp: 1654090240.0000 - _runtime: 2149.0000\n",
      "Epoch 163/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 322.6107 - val_loss: 942.8252 - _timestamp: 1654090250.0000 - _runtime: 2159.0000\n",
      "Epoch 164/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 354.9801 - val_loss: 497.4977 - _timestamp: 1654090260.0000 - _runtime: 2169.0000\n",
      "Epoch 165/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 367.8668 - val_loss: 421.6359 - _timestamp: 1654090269.0000 - _runtime: 2178.0000\n",
      "Epoch 166/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 324.9195 - val_loss: 558.8706 - _timestamp: 1654090279.0000 - _runtime: 2188.0000\n",
      "Epoch 167/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 257.8274 - val_loss: 813.3409 - _timestamp: 1654090289.0000 - _runtime: 2198.0000\n",
      "Epoch 168/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 258.4799 - val_loss: 1231.4232 - _timestamp: 1654090299.0000 - _runtime: 2208.0000\n",
      "Epoch 169/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 306.0013 - val_loss: 1179.6125 - _timestamp: 1654090308.0000 - _runtime: 2217.0000\n",
      "Epoch 170/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 255.8383 - val_loss: 1719.7415 - _timestamp: 1654090318.0000 - _runtime: 2227.0000\n",
      "Epoch 171/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 363.4999 - val_loss: 1796.2568 - _timestamp: 1654090327.0000 - _runtime: 2236.0000\n",
      "Epoch 172/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 329.3166 - val_loss: 1745.6309 - _timestamp: 1654090337.0000 - _runtime: 2246.0000\n",
      "Epoch 173/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 294.3075 - val_loss: 1122.3146 - _timestamp: 1654090346.0000 - _runtime: 2255.0000\n",
      "Epoch 174/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 292.7792 - val_loss: 702.0593 - _timestamp: 1654090356.0000 - _runtime: 2265.0000\n",
      "Epoch 175/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 330.1467 - val_loss: 855.2874 - _timestamp: 1654090366.0000 - _runtime: 2275.0000\n",
      "Epoch 176/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 345.6234 - val_loss: 425.2280 - _timestamp: 1654090376.0000 - _runtime: 2285.0000\n",
      "Epoch 177/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 363.3211 - val_loss: 398.3723 - _timestamp: 1654090386.0000 - _runtime: 2295.0000\n",
      "Epoch 178/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 346.9792 - val_loss: 640.5198 - _timestamp: 1654090395.0000 - _runtime: 2304.0000\n",
      "Epoch 179/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 285.6830 - val_loss: 1134.6260 - _timestamp: 1654090405.0000 - _runtime: 2314.0000\n",
      "Epoch 180/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 264.1733 - val_loss: 883.6425 - _timestamp: 1654090414.0000 - _runtime: 2323.0000\n",
      "Epoch 181/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 280.0202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 30s 627ms/step - loss: 280.0202 - val_loss: 359.9662 - _timestamp: 1654090424.0000 - _runtime: 2333.0000\n",
      "Epoch 182/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 305.8891 - val_loss: 458.4097 - _timestamp: 1654090454.0000 - _runtime: 2363.0000\n",
      "Epoch 183/1000\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 361.8591 - val_loss: 561.6440 - _timestamp: 1654090464.0000 - _runtime: 2373.0000\n",
      "Epoch 184/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 278.3058 - val_loss: 757.7629 - _timestamp: 1654090474.0000 - _runtime: 2383.0000\n",
      "Epoch 185/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 389.6356 - val_loss: 689.6554 - _timestamp: 1654090484.0000 - _runtime: 2393.0000\n",
      "Epoch 186/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 300.7840 - val_loss: 674.9880 - _timestamp: 1654090494.0000 - _runtime: 2403.0000\n",
      "Epoch 187/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 346.1148 - val_loss: 661.8467 - _timestamp: 1654090504.0000 - _runtime: 2413.0000\n",
      "Epoch 188/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 247.6311 - val_loss: 912.6025 - _timestamp: 1654090514.0000 - _runtime: 2423.0000\n",
      "Epoch 189/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 278.8386 - val_loss: 458.7309 - _timestamp: 1654090523.0000 - _runtime: 2432.0000\n",
      "Epoch 190/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 298.7832 - val_loss: 534.3107 - _timestamp: 1654090532.0000 - _runtime: 2441.0000\n",
      "Epoch 191/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 342.7344 - val_loss: 1002.4479 - _timestamp: 1654090542.0000 - _runtime: 2451.0000\n",
      "Epoch 192/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 330.1778 - val_loss: 609.9896 - _timestamp: 1654090552.0000 - _runtime: 2461.0000\n",
      "Epoch 193/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 283.3955 - val_loss: 794.4773 - _timestamp: 1654090561.0000 - _runtime: 2470.0000\n",
      "Epoch 194/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 294.6605 - val_loss: 561.2912 - _timestamp: 1654090570.0000 - _runtime: 2479.0000\n",
      "Epoch 195/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 259.2484 - val_loss: 839.6658 - _timestamp: 1654090580.0000 - _runtime: 2489.0000\n",
      "Epoch 196/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 348.3977 - val_loss: 654.5735 - _timestamp: 1654090590.0000 - _runtime: 2499.0000\n",
      "Epoch 197/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 267.4873 - val_loss: 434.8570 - _timestamp: 1654090600.0000 - _runtime: 2509.0000\n",
      "Epoch 198/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 314.8944 - val_loss: 637.5902 - _timestamp: 1654090610.0000 - _runtime: 2519.0000\n",
      "Epoch 199/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 247.7006 - val_loss: 785.6334 - _timestamp: 1654090620.0000 - _runtime: 2529.0000\n",
      "Epoch 200/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 350.7193 - val_loss: 609.6913 - _timestamp: 1654090629.0000 - _runtime: 2538.0000\n",
      "Epoch 201/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 363.7583 - val_loss: 940.5493 - _timestamp: 1654090639.0000 - _runtime: 2548.0000\n",
      "Epoch 202/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 262.8102 - val_loss: 1012.4600 - _timestamp: 1654090649.0000 - _runtime: 2558.0000\n",
      "Epoch 203/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 314.9069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 24s 489ms/step - loss: 314.9069 - val_loss: 308.3481 - _timestamp: 1654090658.0000 - _runtime: 2567.0000\n",
      "Epoch 204/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 368.3463 - val_loss: 345.3691 - _timestamp: 1654090682.0000 - _runtime: 2591.0000\n",
      "Epoch 205/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 311.2381 - val_loss: 407.0124 - _timestamp: 1654090693.0000 - _runtime: 2602.0000\n",
      "Epoch 206/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 311.9523 - val_loss: 331.8922 - _timestamp: 1654090702.0000 - _runtime: 2611.0000\n",
      "Epoch 207/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 339.7025 - val_loss: 362.7655 - _timestamp: 1654090712.0000 - _runtime: 2621.0000\n",
      "Epoch 208/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 368.2351 - val_loss: 516.3417 - _timestamp: 1654090722.0000 - _runtime: 2631.0000\n",
      "Epoch 209/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 292.2759 - val_loss: 660.5608 - _timestamp: 1654090731.0000 - _runtime: 2640.0000\n",
      "Epoch 210/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 365.6705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 24s 492ms/step - loss: 365.6705 - val_loss: 279.0865 - _timestamp: 1654090741.0000 - _runtime: 2650.0000\n",
      "Epoch 211/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 273.3904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 23s 481ms/step - loss: 273.3904 - val_loss: 220.3976 - _timestamp: 1654090765.0000 - _runtime: 2674.0000\n",
      "Epoch 212/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 233.1712 - val_loss: 563.4642 - _timestamp: 1654090788.0000 - _runtime: 2697.0000\n",
      "Epoch 213/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 344.2546 - val_loss: 618.9197 - _timestamp: 1654090798.0000 - _runtime: 2707.0000\n",
      "Epoch 214/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 321.7835 - val_loss: 393.3495 - _timestamp: 1654090808.0000 - _runtime: 2717.0000\n",
      "Epoch 215/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 298.2714 - val_loss: 395.6992 - _timestamp: 1654090818.0000 - _runtime: 2727.0000\n",
      "Epoch 216/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 265.2063 - val_loss: 297.0765 - _timestamp: 1654090828.0000 - _runtime: 2737.0000\n",
      "Epoch 217/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 239.3710 - val_loss: 328.2146 - _timestamp: 1654090838.0000 - _runtime: 2747.0000\n",
      "Epoch 218/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 279.2229 - val_loss: 599.1859 - _timestamp: 1654090848.0000 - _runtime: 2757.0000\n",
      "Epoch 219/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 336.3895 - val_loss: 573.7119 - _timestamp: 1654090857.0000 - _runtime: 2766.0000\n",
      "Epoch 220/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 262.7728 - val_loss: 608.1415 - _timestamp: 1654090867.0000 - _runtime: 2776.0000\n",
      "Epoch 221/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 288.6486 - val_loss: 545.1342 - _timestamp: 1654090877.0000 - _runtime: 2786.0000\n",
      "Epoch 222/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 314.2117 - val_loss: 456.1560 - _timestamp: 1654090887.0000 - _runtime: 2796.0000\n",
      "Epoch 223/1000\n",
      "49/49 [==============================] - 11s 216ms/step - loss: 301.7806 - val_loss: 389.1707 - _timestamp: 1654090897.0000 - _runtime: 2806.0000\n",
      "Epoch 224/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 342.2140 - val_loss: 356.4846 - _timestamp: 1654090917.0000 - _runtime: 2826.0000\n",
      "Epoch 225/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 255.1888 - val_loss: 362.1957 - _timestamp: 1654090926.0000 - _runtime: 2835.0000\n",
      "Epoch 226/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 410.2209 - val_loss: 5055.0176 - _timestamp: 1654090936.0000 - _runtime: 2845.0000\n",
      "Epoch 227/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 256.8235 - val_loss: 904.1159 - _timestamp: 1654090946.0000 - _runtime: 2855.0000\n",
      "Epoch 228/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 269.4841 - val_loss: 691.3151 - _timestamp: 1654090955.0000 - _runtime: 2864.0000\n",
      "Epoch 229/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 317.4785 - val_loss: 449.7602 - _timestamp: 1654090965.0000 - _runtime: 2874.0000\n",
      "Epoch 230/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 269.3430 - val_loss: 892.3245 - _timestamp: 1654090974.0000 - _runtime: 2883.0000\n",
      "Epoch 231/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 281.0990 - val_loss: 582.7339 - _timestamp: 1654090984.0000 - _runtime: 2893.0000\n",
      "Epoch 232/1000\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 368.5030 - val_loss: 825.6357 - _timestamp: 1654090994.0000 - _runtime: 2903.0000\n",
      "Epoch 233/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 381.6701 - val_loss: 1599.2556 - _timestamp: 1654091004.0000 - _runtime: 2913.0000\n",
      "Epoch 234/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 286.7657 - val_loss: 792.9673 - _timestamp: 1654091014.0000 - _runtime: 2923.0000\n",
      "Epoch 235/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 221.4416 - val_loss: 908.4750 - _timestamp: 1654091024.0000 - _runtime: 2933.0000\n",
      "Epoch 236/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 336.3387 - val_loss: 703.6361 - _timestamp: 1654091034.0000 - _runtime: 2943.0000\n",
      "Epoch 237/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 267.8329 - val_loss: 1795.9209 - _timestamp: 1654091044.0000 - _runtime: 2953.0000\n",
      "Epoch 238/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 289.9246 - val_loss: 1092.1771 - _timestamp: 1654091054.0000 - _runtime: 2963.0000\n",
      "Epoch 239/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 267.8141 - val_loss: 1557.6747 - _timestamp: 1654091063.0000 - _runtime: 2972.0000\n",
      "Epoch 240/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 277.4684 - val_loss: 337.6801 - _timestamp: 1654091073.0000 - _runtime: 2982.0000\n",
      "Epoch 241/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 290.4354 - val_loss: 317.5454 - _timestamp: 1654091083.0000 - _runtime: 2992.0000\n",
      "Epoch 242/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 257.8830 - val_loss: 762.3617 - _timestamp: 1654091093.0000 - _runtime: 3002.0000\n",
      "Epoch 243/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 252.8134 - val_loss: 603.3661 - _timestamp: 1654091102.0000 - _runtime: 3011.0000\n",
      "Epoch 244/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 287.0318 - val_loss: 542.0379 - _timestamp: 1654091113.0000 - _runtime: 3022.0000\n",
      "Epoch 245/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 341.3047 - val_loss: 641.5170 - _timestamp: 1654091123.0000 - _runtime: 3032.0000\n",
      "Epoch 246/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 249.4233 - val_loss: 690.7217 - _timestamp: 1654091132.0000 - _runtime: 3041.0000\n",
      "Epoch 247/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 358.1426 - val_loss: 462.0449 - _timestamp: 1654091142.0000 - _runtime: 3051.0000\n",
      "Epoch 248/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 285.5164 - val_loss: 719.9429 - _timestamp: 1654091152.0000 - _runtime: 3061.0000\n",
      "Epoch 249/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 285.4845 - val_loss: 511.6054 - _timestamp: 1654091161.0000 - _runtime: 3070.0000\n",
      "Epoch 250/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 216.6431 - val_loss: 620.1230 - _timestamp: 1654091171.0000 - _runtime: 3080.0000\n",
      "Epoch 251/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 263.1089 - val_loss: 264.6181 - _timestamp: 1654091181.0000 - _runtime: 3090.0000\n",
      "Epoch 252/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 322.5863 - val_loss: 1609.8719 - _timestamp: 1654091191.0000 - _runtime: 3100.0000\n",
      "Epoch 253/1000\n",
      "49/49 [==============================] - 10s 211ms/step - loss: 362.6539 - val_loss: 276.0129 - _timestamp: 1654091202.0000 - _runtime: 3111.0000\n",
      "Epoch 254/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 288.4014 - val_loss: 326.7304 - _timestamp: 1654091222.0000 - _runtime: 3131.0000\n",
      "Epoch 255/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 313.7542 - val_loss: 822.1635 - _timestamp: 1654091231.0000 - _runtime: 3140.0000\n",
      "Epoch 256/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 280.0005 - val_loss: 980.6181 - _timestamp: 1654091242.0000 - _runtime: 3151.0000\n",
      "Epoch 257/1000\n",
      "49/49 [==============================] - 10s 206ms/step - loss: 233.7429 - val_loss: 268.2913 - _timestamp: 1654091252.0000 - _runtime: 3161.0000\n",
      "Epoch 258/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 258.2590 - val_loss: 300.0103 - _timestamp: 1654091262.0000 - _runtime: 3171.0000\n",
      "Epoch 259/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 254.3094 - val_loss: 604.2163 - _timestamp: 1654091272.0000 - _runtime: 3181.0000\n",
      "Epoch 260/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 275.4186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 24s 487ms/step - loss: 275.4186 - val_loss: 186.5386 - _timestamp: 1654091281.0000 - _runtime: 3190.0000\n",
      "Epoch 261/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 244.6176 - val_loss: 197.0961 - _timestamp: 1654091305.0000 - _runtime: 3214.0000\n",
      "Epoch 262/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 266.3876 - val_loss: 468.6776 - _timestamp: 1654091315.0000 - _runtime: 3224.0000\n",
      "Epoch 263/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 312.1444 - val_loss: 511.9681 - _timestamp: 1654091325.0000 - _runtime: 3234.0000\n",
      "Epoch 264/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 318.8267 - val_loss: 680.7812 - _timestamp: 1654091334.0000 - _runtime: 3243.0000\n",
      "Epoch 265/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 251.4127 - val_loss: 424.8314 - _timestamp: 1654091344.0000 - _runtime: 3253.0000\n",
      "Epoch 266/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 232.5510 - val_loss: 587.5702 - _timestamp: 1654091354.0000 - _runtime: 3263.0000\n",
      "Epoch 267/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 279.6635 - val_loss: 1256.4526 - _timestamp: 1654091363.0000 - _runtime: 3272.0000\n",
      "Epoch 268/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 283.1649 - val_loss: 1016.1017 - _timestamp: 1654091372.0000 - _runtime: 3281.0000\n",
      "Epoch 269/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 350.9676 - val_loss: 384.1692 - _timestamp: 1654091382.0000 - _runtime: 3291.0000\n",
      "Epoch 270/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 228.4919 - val_loss: 466.6067 - _timestamp: 1654091392.0000 - _runtime: 3301.0000\n",
      "Epoch 271/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 299.1328 - val_loss: 1324.0942 - _timestamp: 1654091401.0000 - _runtime: 3310.0000\n",
      "Epoch 272/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 331.5725 - val_loss: 754.2598 - _timestamp: 1654091411.0000 - _runtime: 3320.0000\n",
      "Epoch 273/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 258.4577 - val_loss: 915.4662 - _timestamp: 1654091420.0000 - _runtime: 3329.0000\n",
      "Epoch 274/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 315.5295 - val_loss: 321.8441 - _timestamp: 1654091430.0000 - _runtime: 3339.0000\n",
      "Epoch 275/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 293.3670 - val_loss: 524.5627 - _timestamp: 1654091440.0000 - _runtime: 3349.0000\n",
      "Epoch 276/1000\n",
      "49/49 [==============================] - 10s 212ms/step - loss: 271.9305 - val_loss: 346.3150 - _timestamp: 1654091450.0000 - _runtime: 3359.0000\n",
      "Epoch 277/1000\n",
      "49/49 [==============================] - 10s 210ms/step - loss: 300.1296 - val_loss: 430.7018 - _timestamp: 1654091461.0000 - _runtime: 3370.0000\n",
      "Epoch 278/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 252.6934 - val_loss: 546.8770 - _timestamp: 1654091470.0000 - _runtime: 3379.0000\n",
      "Epoch 279/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 266.4221 - val_loss: 238.8477 - _timestamp: 1654091480.0000 - _runtime: 3389.0000\n",
      "Epoch 280/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 258.9155 - val_loss: 228.8100 - _timestamp: 1654091490.0000 - _runtime: 3399.0000\n",
      "Epoch 281/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 236.0081 - val_loss: 325.3613 - _timestamp: 1654091500.0000 - _runtime: 3409.0000\n",
      "Epoch 282/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 258.9095 - val_loss: 829.5867 - _timestamp: 1654091509.0000 - _runtime: 3418.0000\n",
      "Epoch 283/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 299.0934 - val_loss: 273.0757 - _timestamp: 1654091519.0000 - _runtime: 3428.0000\n",
      "Epoch 284/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 268.2356 - val_loss: 211.7153 - _timestamp: 1654091529.0000 - _runtime: 3438.0000\n",
      "Epoch 285/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 286.7264 - val_loss: 344.4284 - _timestamp: 1654091538.0000 - _runtime: 3447.0000\n",
      "Epoch 286/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 266.1421 - val_loss: 975.8539 - _timestamp: 1654091548.0000 - _runtime: 3457.0000\n",
      "Epoch 287/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 223.2974 - val_loss: 736.6415 - _timestamp: 1654091558.0000 - _runtime: 3467.0000\n",
      "Epoch 288/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 277.4726 - val_loss: 1524.8021 - _timestamp: 1654091567.0000 - _runtime: 3476.0000\n",
      "Epoch 289/1000\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 301.0612 - val_loss: 1159.1091 - _timestamp: 1654091578.0000 - _runtime: 3487.0000\n",
      "Epoch 290/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 234.7319 - val_loss: 465.8098 - _timestamp: 1654091588.0000 - _runtime: 3497.0000\n",
      "Epoch 291/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 230.1115 - val_loss: 287.0400 - _timestamp: 1654091598.0000 - _runtime: 3507.0000\n",
      "Epoch 292/1000\n",
      "49/49 [==============================] - 10s 207ms/step - loss: 212.8564 - val_loss: 909.1526 - _timestamp: 1654091608.0000 - _runtime: 3517.0000\n",
      "Epoch 293/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 244.5585 - val_loss: 572.5173 - _timestamp: 1654091617.0000 - _runtime: 3526.0000\n",
      "Epoch 294/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 286.4720 - val_loss: 964.8876 - _timestamp: 1654091627.0000 - _runtime: 3536.0000\n",
      "Epoch 295/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 205.6358 - val_loss: 1017.3113 - _timestamp: 1654091637.0000 - _runtime: 3546.0000\n",
      "Epoch 296/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 324.6974 - val_loss: 1847.5524 - _timestamp: 1654091647.0000 - _runtime: 3556.0000\n",
      "Epoch 297/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 308.8337 - val_loss: 791.6752 - _timestamp: 1654091657.0000 - _runtime: 3566.0000\n",
      "Epoch 298/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 261.6411 - val_loss: 760.5698 - _timestamp: 1654091666.0000 - _runtime: 3575.0000\n",
      "Epoch 299/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 203.6049 - val_loss: 1192.6351 - _timestamp: 1654091676.0000 - _runtime: 3585.0000\n",
      "Epoch 300/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 270.0691 - val_loss: 977.6767 - _timestamp: 1654091686.0000 - _runtime: 3595.0000\n",
      "Epoch 301/1000\n",
      "49/49 [==============================] - 10s 191ms/step - loss: 234.6549 - val_loss: 585.2789 - _timestamp: 1654091695.0000 - _runtime: 3604.0000\n",
      "Epoch 302/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 340.7618 - val_loss: 796.9066 - _timestamp: 1654091705.0000 - _runtime: 3614.0000\n",
      "Epoch 303/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 233.2516 - val_loss: 764.8969 - _timestamp: 1654091714.0000 - _runtime: 3623.0000\n",
      "Epoch 304/1000\n",
      "49/49 [==============================] - 10s 195ms/step - loss: 224.6812 - val_loss: 319.3439 - _timestamp: 1654091724.0000 - _runtime: 3633.0000\n",
      "Epoch 305/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 272.6349 - val_loss: 352.4803 - _timestamp: 1654091734.0000 - _runtime: 3643.0000\n",
      "Epoch 306/1000\n",
      "49/49 [==============================] - 9s 193ms/step - loss: 295.7101 - val_loss: 443.3941 - _timestamp: 1654091744.0000 - _runtime: 3653.0000\n",
      "Epoch 307/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 276.7626 - val_loss: 324.7907 - _timestamp: 1654091753.0000 - _runtime: 3662.0000\n",
      "Epoch 308/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 273.2428 - val_loss: 518.5628 - _timestamp: 1654091763.0000 - _runtime: 3672.0000\n",
      "Epoch 309/1000\n",
      "49/49 [==============================] - 10s 204ms/step - loss: 313.3209 - val_loss: 295.1928 - _timestamp: 1654091773.0000 - _runtime: 3682.0000\n",
      "Epoch 310/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 254.0483 - val_loss: 415.4817 - _timestamp: 1654091782.0000 - _runtime: 3691.0000\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 9s 193ms/step - loss: 279.3907 - val_loss: 255.8272 - _timestamp: 1654091792.0000 - _runtime: 3701.0000\n",
      "Epoch 312/1000\n",
      "49/49 [==============================] - 10s 201ms/step - loss: 291.2692 - val_loss: 685.8195 - _timestamp: 1654091802.0000 - _runtime: 3711.0000\n",
      "Epoch 313/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 254.9335 - val_loss: 566.6274 - _timestamp: 1654091812.0000 - _runtime: 3721.0000\n",
      "Epoch 314/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 238.7918 - val_loss: 1350.7382 - _timestamp: 1654091821.0000 - _runtime: 3730.0000\n",
      "Epoch 315/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 253.6813 - val_loss: 327.9747 - _timestamp: 1654091830.0000 - _runtime: 3739.0000\n",
      "Epoch 316/1000\n",
      "49/49 [==============================] - 10s 199ms/step - loss: 267.4687 - val_loss: 328.0549 - _timestamp: 1654091840.0000 - _runtime: 3749.0000\n",
      "Epoch 317/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 238.5634 - val_loss: 383.8845 - _timestamp: 1654091850.0000 - _runtime: 3759.0000\n",
      "Epoch 318/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 228.4200 - val_loss: 1214.2051 - _timestamp: 1654091860.0000 - _runtime: 3769.0000\n",
      "Epoch 319/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 258.4755 - val_loss: 350.1104 - _timestamp: 1654091869.0000 - _runtime: 3778.0000\n",
      "Epoch 320/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 252.1509 - val_loss: 310.0661 - _timestamp: 1654091879.0000 - _runtime: 3788.0000\n",
      "Epoch 321/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 305.8472 - val_loss: 1015.8288 - _timestamp: 1654091889.0000 - _runtime: 3798.0000\n",
      "Epoch 322/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 227.7710 - val_loss: 718.7018 - _timestamp: 1654091899.0000 - _runtime: 3808.0000\n",
      "Epoch 323/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 223.1263 - val_loss: 369.3429 - _timestamp: 1654091909.0000 - _runtime: 3818.0000\n",
      "Epoch 324/1000\n",
      "49/49 [==============================] - 10s 203ms/step - loss: 242.0672 - val_loss: 311.1373 - _timestamp: 1654091919.0000 - _runtime: 3828.0000\n",
      "Epoch 325/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 227.1852 - val_loss: 285.3504 - _timestamp: 1654091928.0000 - _runtime: 3837.0000\n",
      "Epoch 326/1000\n",
      "49/49 [==============================] - 9s 194ms/step - loss: 371.6869 - val_loss: 198.3683 - _timestamp: 1654091938.0000 - _runtime: 3847.0000\n",
      "Epoch 327/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 233.8388 - val_loss: 190.8764 - _timestamp: 1654091947.0000 - _runtime: 3856.0000\n",
      "Epoch 328/1000\n",
      "49/49 [==============================] - 10s 198ms/step - loss: 261.9932 - val_loss: 229.9316 - _timestamp: 1654091957.0000 - _runtime: 3866.0000\n",
      "Epoch 329/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 279.3020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 42s 870ms/step - loss: 279.3020 - val_loss: 173.4142 - _timestamp: 1654091967.0000 - _runtime: 3876.0000\n",
      "Epoch 330/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 289.5269 - val_loss: 342.7911 - _timestamp: 1654092009.0000 - _runtime: 3918.0000\n",
      "Epoch 331/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 216.8828 - val_loss: 290.5810 - _timestamp: 1654092019.0000 - _runtime: 3928.0000\n",
      "Epoch 332/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 214.3011 - val_loss: 275.7024 - _timestamp: 1654092028.0000 - _runtime: 3937.0000\n",
      "Epoch 333/1000\n",
      "49/49 [==============================] - 10s 202ms/step - loss: 303.1465 - val_loss: 311.7207 - _timestamp: 1654092038.0000 - _runtime: 3947.0000\n",
      "Epoch 334/1000\n",
      "49/49 [==============================] - 10s 196ms/step - loss: 258.8170 - val_loss: 274.9532 - _timestamp: 1654092048.0000 - _runtime: 3957.0000\n",
      "Epoch 335/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 223.5997 - val_loss: 536.2292 - _timestamp: 1654092058.0000 - _runtime: 3967.0000\n",
      "Epoch 336/1000\n",
      "49/49 [==============================] - 9s 186ms/step - loss: 240.3187 - val_loss: 665.9970 - _timestamp: 1654092067.0000 - _runtime: 3976.0000\n",
      "Epoch 337/1000\n",
      "49/49 [==============================] - 9s 183ms/step - loss: 334.1545 - val_loss: 421.2114 - _timestamp: 1654092076.0000 - _runtime: 3985.0000\n",
      "Epoch 338/1000\n",
      "49/49 [==============================] - 10s 205ms/step - loss: 221.0977 - val_loss: 282.4509 - _timestamp: 1654092086.0000 - _runtime: 3995.0000\n",
      "Epoch 339/1000\n",
      "49/49 [==============================] - 8s 165ms/step - loss: 216.1190 - val_loss: 315.2199 - _timestamp: 1654092095.0000 - _runtime: 4004.0000\n",
      "Epoch 340/1000\n",
      "49/49 [==============================] - 9s 178ms/step - loss: 227.9309 - val_loss: 229.6775 - _timestamp: 1654092103.0000 - _runtime: 4012.0000\n",
      "Epoch 341/1000\n",
      "49/49 [==============================] - 11s 218ms/step - loss: 249.9810 - val_loss: 253.5235 - _timestamp: 1654092114.0000 - _runtime: 4023.0000\n",
      "Epoch 342/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 248.2113 - val_loss: 403.3978 - _timestamp: 1654092124.0000 - _runtime: 4033.0000\n",
      "Epoch 343/1000\n",
      "49/49 [==============================] - 10s 193ms/step - loss: 239.7137 - val_loss: 344.4668 - _timestamp: 1654092133.0000 - _runtime: 4042.0000\n",
      "Epoch 344/1000\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 282.9669 - val_loss: 331.5674 - _timestamp: 1654092142.0000 - _runtime: 4051.0000\n",
      "Epoch 345/1000\n",
      "49/49 [==============================] - 10s 197ms/step - loss: 256.4314 - val_loss: 862.1794 - _timestamp: 1654092152.0000 - _runtime: 4061.0000\n",
      "Epoch 346/1000\n",
      "49/49 [==============================] - 7s 146ms/step - loss: 230.2901 - val_loss: 418.3643 - _timestamp: 1654092159.0000 - _runtime: 4068.0000\n",
      "Epoch 347/1000\n",
      "49/49 [==============================] - 11s 235ms/step - loss: 228.1767 - val_loss: 834.0071 - _timestamp: 1654092171.0000 - _runtime: 4080.0000\n",
      "Epoch 348/1000\n",
      "49/49 [==============================] - 11s 224ms/step - loss: 221.4699 - val_loss: 322.0710 - _timestamp: 1654092182.0000 - _runtime: 4091.0000\n",
      "Epoch 349/1000\n",
      "49/49 [==============================] - 10s 208ms/step - loss: 242.5033 - val_loss: 311.9756 - _timestamp: 1654092192.0000 - _runtime: 4101.0000\n",
      "Epoch 350/1000\n",
      "49/49 [==============================] - 12s 238ms/step - loss: 233.1171 - val_loss: 291.6129 - _timestamp: 1654092215.0000 - _runtime: 4124.0000\n",
      "Epoch 351/1000\n",
      "49/49 [==============================] - 9s 187ms/step - loss: 230.8264 - val_loss: 371.9087 - _timestamp: 1654092224.0000 - _runtime: 4133.0000\n",
      "Epoch 352/1000\n",
      "49/49 [==============================] - 11s 228ms/step - loss: 271.4426 - val_loss: 533.6825 - _timestamp: 1654092236.0000 - _runtime: 4145.0000\n",
      "Epoch 353/1000\n",
      "49/49 [==============================] - 11s 231ms/step - loss: 200.7093 - val_loss: 295.6128 - _timestamp: 1654092244.0000 - _runtime: 4153.0000\n",
      "Epoch 354/1000\n",
      "49/49 [==============================] - 9s 185ms/step - loss: 214.2200 - val_loss: 246.6819 - _timestamp: 1654092256.0000 - _runtime: 4165.0000\n",
      "Epoch 355/1000\n",
      "49/49 [==============================] - 9s 175ms/step - loss: 245.8182 - val_loss: 242.1484 - _timestamp: 1654092265.0000 - _runtime: 4174.0000\n",
      "Epoch 356/1000\n",
      "49/49 [==============================] - 9s 179ms/step - loss: 269.2262 - val_loss: 423.7367 - _timestamp: 1654092274.0000 - _runtime: 4183.0000\n",
      "Epoch 357/1000\n",
      "49/49 [==============================] - 10s 194ms/step - loss: 231.6937 - val_loss: 418.5429 - _timestamp: 1654092283.0000 - _runtime: 4192.0000\n",
      "Epoch 358/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 254.0302 - val_loss: 423.0978 - _timestamp: 1654092293.0000 - _runtime: 4202.0000\n",
      "Epoch 359/1000\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 321.3244 - val_loss: 489.9804 - _timestamp: 1654092303.0000 - _runtime: 4212.0000\n",
      "Epoch 360/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 245.3021 - val_loss: 948.4697 - _timestamp: 1654092312.0000 - _runtime: 4221.0000\n",
      "Epoch 361/1000\n",
      "49/49 [==============================] - 9s 188ms/step - loss: 242.7911 - val_loss: 585.1923 - _timestamp: 1654092322.0000 - _runtime: 4231.0000\n",
      "Epoch 362/1000\n",
      "49/49 [==============================] - 9s 185ms/step - loss: 269.4749 - val_loss: 746.3357 - _timestamp: 1654092331.0000 - _runtime: 4240.0000\n",
      "Epoch 363/1000\n",
      "49/49 [==============================] - 17s 341ms/step - loss: 178.2666 - val_loss: 433.5536 - _timestamp: 1654092338.0000 - _runtime: 4247.0000\n",
      "Epoch 364/1000\n",
      "49/49 [==============================] - 7s 149ms/step - loss: 201.2605 - val_loss: 374.0061 - _timestamp: 1654092355.0000 - _runtime: 4264.0000\n",
      "Epoch 365/1000\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 240.6320 - val_loss: 1145.7300 - _timestamp: 1654092362.0000 - _runtime: 4271.0000\n",
      "Epoch 366/1000\n",
      "49/49 [==============================] - 8s 160ms/step - loss: 243.8727 - val_loss: 498.1191 - _timestamp: 1654092370.0000 - _runtime: 4279.0000\n",
      "Epoch 367/1000\n",
      "49/49 [==============================] - 8s 153ms/step - loss: 247.1820 - val_loss: 747.0682 - _timestamp: 1654092377.0000 - _runtime: 4286.0000\n",
      "Epoch 368/1000\n",
      "49/49 [==============================] - 11s 209ms/step - loss: 263.2153 - val_loss: 559.4886 - _timestamp: 1654092388.0000 - _runtime: 4297.0000\n",
      "Epoch 369/1000\n",
      "49/49 [==============================] - 12s 236ms/step - loss: 189.2938 - val_loss: 251.1328 - _timestamp: 1654092400.0000 - _runtime: 4309.0000\n",
      "Epoch 370/1000\n",
      "49/49 [==============================] - 9s 185ms/step - loss: 272.1305 - val_loss: 660.1168 - _timestamp: 1654092418.0000 - _runtime: 4327.0000\n",
      "Epoch 371/1000\n",
      "49/49 [==============================] - 11s 224ms/step - loss: 196.5816 - val_loss: 750.8190 - _timestamp: 1654092429.0000 - _runtime: 4338.0000\n",
      "Epoch 372/1000\n",
      "49/49 [==============================] - 11s 234ms/step - loss: 199.7869 - val_loss: 411.1951 - _timestamp: 1654092440.0000 - _runtime: 4349.0000\n",
      "Epoch 373/1000\n",
      "49/49 [==============================] - 12s 218ms/step - loss: 243.0688 - val_loss: 318.1626 - _timestamp: 1654092452.0000 - _runtime: 4361.0000\n",
      "Epoch 374/1000\n",
      "49/49 [==============================] - 12s 234ms/step - loss: 254.7531 - val_loss: 489.4297 - _timestamp: 1654092464.0000 - _runtime: 4373.0000\n",
      "Epoch 375/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 232.0612 - val_loss: 1084.9340 - _timestamp: 1654092473.0000 - _runtime: 4382.0000\n",
      "Epoch 376/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 258.4493 - val_loss: 362.5037 - _timestamp: 1654092483.0000 - _runtime: 4392.0000\n",
      "Epoch 377/1000\n",
      "49/49 [==============================] - 10s 200ms/step - loss: 212.1979 - val_loss: 320.6721 - _timestamp: 1654092493.0000 - _runtime: 4402.0000\n",
      "Epoch 378/1000\n",
      "49/49 [==============================] - 8s 170ms/step - loss: 256.7180 - val_loss: 395.8668 - _timestamp: 1654092502.0000 - _runtime: 4411.0000\n",
      "Epoch 379/1000\n",
      "49/49 [==============================] - 7s 142ms/step - loss: 212.8436 - val_loss: 403.9927 - _timestamp: 1654092509.0000 - _runtime: 4418.0000\n",
      "Epoch 380/1000\n",
      "49/49 [==============================] - 7s 150ms/step - loss: 215.9442 - val_loss: 1615.7830 - _timestamp: 1654092516.0000 - _runtime: 4425.0000\n",
      "Epoch 381/1000\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 270.5675 - val_loss: 1061.3048 - _timestamp: 1654092525.0000 - _runtime: 4434.0000\n",
      "Epoch 382/1000\n",
      "49/49 [==============================] - 9s 190ms/step - loss: 202.4467 - val_loss: 1172.4388 - _timestamp: 1654092536.0000 - _runtime: 4445.0000\n",
      "Epoch 383/1000\n",
      "49/49 [==============================] - 9s 186ms/step - loss: 318.4318 - val_loss: 934.7465 - _timestamp: 1654092546.0000 - _runtime: 4455.0000\n",
      "Epoch 384/1000\n",
      "49/49 [==============================] - 10s 211ms/step - loss: 318.6269 - val_loss: 614.4098 - _timestamp: 1654092557.0000 - _runtime: 4466.0000\n",
      "Epoch 385/1000\n",
      "49/49 [==============================] - 11s 210ms/step - loss: 254.5762 - val_loss: 591.6012 - _timestamp: 1654092568.0000 - _runtime: 4477.0000\n",
      "Epoch 386/1000\n",
      "49/49 [==============================] - 11s 228ms/step - loss: 238.7727 - val_loss: 309.2701 - _timestamp: 1654092579.0000 - _runtime: 4488.0000\n",
      "Epoch 387/1000\n",
      "49/49 [==============================] - 15s 298ms/step - loss: 207.4615 - val_loss: 442.4854 - _timestamp: 1654092594.0000 - _runtime: 4503.0000\n",
      "Epoch 388/1000\n",
      "49/49 [==============================] - 13s 252ms/step - loss: 261.7116 - val_loss: 416.6094 - _timestamp: 1654092612.0000 - _runtime: 4521.0000\n",
      "Epoch 389/1000\n",
      "49/49 [==============================] - 13s 276ms/step - loss: 260.8360 - val_loss: 838.6316 - _timestamp: 1654092626.0000 - _runtime: 4535.0000\n",
      "Epoch 390/1000\n",
      "49/49 [==============================] - 13s 267ms/step - loss: 316.7797 - val_loss: 3085.1189 - _timestamp: 1654092639.0000 - _runtime: 4548.0000\n",
      "Epoch 391/1000\n",
      "49/49 [==============================] - 13s 268ms/step - loss: 313.0596 - val_loss: 850.6229 - _timestamp: 1654092652.0000 - _runtime: 4561.0000\n",
      "Epoch 392/1000\n",
      "49/49 [==============================] - 9s 191ms/step - loss: 259.6462 - val_loss: 686.5600 - _timestamp: 1654092662.0000 - _runtime: 4571.0000\n",
      "Epoch 393/1000\n",
      "49/49 [==============================] - 12s 244ms/step - loss: 357.6761 - val_loss: 747.8083 - _timestamp: 1654092674.0000 - _runtime: 4583.0000\n",
      "Epoch 394/1000\n",
      "49/49 [==============================] - 9s 192ms/step - loss: 255.6279 - val_loss: 283.9961 - _timestamp: 1654092683.0000 - _runtime: 4592.0000\n",
      "Epoch 395/1000\n",
      "49/49 [==============================] - 13s 260ms/step - loss: 357.1119 - val_loss: 326.0534 - _timestamp: 1654092697.0000 - _runtime: 4606.0000\n",
      "Epoch 396/1000\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 272.9230 - val_loss: 301.8712 - _timestamp: 1654092709.0000 - _runtime: 4618.0000\n",
      "Epoch 397/1000\n",
      "49/49 [==============================] - 11s 227ms/step - loss: 271.8891 - val_loss: 557.6965 - _timestamp: 1654092720.0000 - _runtime: 4629.0000\n",
      "Epoch 398/1000\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 242.3598 - val_loss: 501.5659 - _timestamp: 1654092735.0000 - _runtime: 4644.0000\n",
      "Epoch 399/1000\n",
      "49/49 [==============================] - 15s 311ms/step - loss: 267.6568 - val_loss: 386.2122 - _timestamp: 1654092750.0000 - _runtime: 4659.0000\n",
      "Epoch 400/1000\n",
      "49/49 [==============================] - 14s 293ms/step - loss: 207.5811 - val_loss: 556.9885 - _timestamp: 1654092770.0000 - _runtime: 4679.0000\n",
      "Epoch 401/1000\n",
      "49/49 [==============================] - 14s 287ms/step - loss: 267.3742 - val_loss: 248.5977 - _timestamp: 1654092784.0000 - _runtime: 4693.0000\n",
      "Epoch 402/1000\n",
      "49/49 [==============================] - 18s 361ms/step - loss: 271.1920 - val_loss: 579.9673 - _timestamp: 1654092808.0000 - _runtime: 4717.0000\n",
      "Epoch 403/1000\n",
      "49/49 [==============================] - 20s 398ms/step - loss: 215.3145 - val_loss: 564.4634 - _timestamp: 1654092828.0000 - _runtime: 4737.0000\n",
      "Epoch 404/1000\n",
      "49/49 [==============================] - 18s 361ms/step - loss: 227.2346 - val_loss: 511.2609 - _timestamp: 1654092845.0000 - _runtime: 4754.0000\n",
      "Epoch 405/1000\n",
      "49/49 [==============================] - 15s 297ms/step - loss: 242.7392 - val_loss: 428.5402 - _timestamp: 1654092863.0000 - _runtime: 4772.0000\n",
      "Epoch 406/1000\n",
      "49/49 [==============================] - 19s 396ms/step - loss: 248.2702 - val_loss: 441.3871 - _timestamp: 1654092882.0000 - _runtime: 4791.0000\n",
      "Epoch 407/1000\n",
      "49/49 [==============================] - 18s 357ms/step - loss: 242.4695 - val_loss: 312.3545 - _timestamp: 1654092900.0000 - _runtime: 4809.0000\n",
      "Epoch 408/1000\n",
      "49/49 [==============================] - 16s 320ms/step - loss: 199.4358 - val_loss: 850.0462 - _timestamp: 1654092919.0000 - _runtime: 4828.0000\n",
      "Epoch 409/1000\n",
      "49/49 [==============================] - 16s 321ms/step - loss: 191.5706 - val_loss: 826.8201 - _timestamp: 1654092935.0000 - _runtime: 4844.0000\n",
      "Epoch 410/1000\n",
      "49/49 [==============================] - 15s 311ms/step - loss: 262.0622 - val_loss: 319.7087 - _timestamp: 1654092955.0000 - _runtime: 4864.0000\n",
      "Epoch 411/1000\n",
      "49/49 [==============================] - 17s 340ms/step - loss: 245.2850 - val_loss: 376.8071 - _timestamp: 1654092976.0000 - _runtime: 4885.0000\n",
      "Epoch 412/1000\n",
      "49/49 [==============================] - 16s 325ms/step - loss: 198.7127 - val_loss: 632.3643 - _timestamp: 1654092992.0000 - _runtime: 4901.0000\n",
      "Epoch 413/1000\n",
      "49/49 [==============================] - 16s 326ms/step - loss: 203.8838 - val_loss: 432.2672 - _timestamp: 1654093009.0000 - _runtime: 4918.0000\n",
      "Epoch 414/1000\n",
      "49/49 [==============================] - 16s 334ms/step - loss: 212.0426 - val_loss: 243.6828 - _timestamp: 1654093025.0000 - _runtime: 4934.0000\n",
      "Epoch 415/1000\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 217.2661 - val_loss: 514.5560 - _timestamp: 1654093038.0000 - _runtime: 4947.0000\n",
      "Epoch 416/1000\n",
      "49/49 [==============================] - 11s 229ms/step - loss: 235.1863 - val_loss: 727.9478 - _timestamp: 1654093049.0000 - _runtime: 4958.0000\n",
      "Epoch 417/1000\n",
      "49/49 [==============================] - 12s 234ms/step - loss: 215.3716 - val_loss: 565.0956 - _timestamp: 1654093070.0000 - _runtime: 4979.0000\n",
      "Epoch 418/1000\n",
      "49/49 [==============================] - 11s 228ms/step - loss: 222.0821 - val_loss: 893.1516 - _timestamp: 1654093081.0000 - _runtime: 4990.0000\n",
      "Epoch 419/1000\n",
      "49/49 [==============================] - 11s 225ms/step - loss: 199.0629 - val_loss: 328.0918 - _timestamp: 1654093092.0000 - _runtime: 5001.0000\n",
      "Epoch 420/1000\n",
      "49/49 [==============================] - 11s 222ms/step - loss: 197.4713 - val_loss: 391.2469 - _timestamp: 1654093103.0000 - _runtime: 5012.0000\n",
      "Epoch 421/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 287.9085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 392s 8s/step - loss: 287.9085 - val_loss: 166.6418 - _timestamp: 1654093114.0000 - _runtime: 5023.0000\n",
      "Epoch 422/1000\n",
      "49/49 [==============================] - 17s 296ms/step - loss: 316.1742 - val_loss: 188.5580 - _timestamp: 1654093515.0000 - _runtime: 5424.0000\n",
      "Epoch 423/1000\n",
      "49/49 [==============================] - 14s 285ms/step - loss: 262.5540 - val_loss: 615.2442 - _timestamp: 1654093533.0000 - _runtime: 5442.0000\n",
      "Epoch 424/1000\n",
      "49/49 [==============================] - 15s 299ms/step - loss: 281.2200 - val_loss: 450.1551 - _timestamp: 1654093554.0000 - _runtime: 5463.0000\n",
      "Epoch 425/1000\n",
      "49/49 [==============================] - 14s 293ms/step - loss: 254.8639 - val_loss: 1422.2186 - _timestamp: 1654093569.0000 - _runtime: 5478.0000\n",
      "Epoch 426/1000\n",
      "49/49 [==============================] - 15s 308ms/step - loss: 231.9596 - val_loss: 747.1530 - _timestamp: 1654093584.0000 - _runtime: 5493.0000\n",
      "Epoch 427/1000\n",
      "49/49 [==============================] - 15s 309ms/step - loss: 179.6725 - val_loss: 555.2182 - _timestamp: 1654093599.0000 - _runtime: 5508.0000\n",
      "Epoch 428/1000\n",
      "49/49 [==============================] - 15s 308ms/step - loss: 256.3366 - val_loss: 331.4524 - _timestamp: 1654093615.0000 - _runtime: 5524.0000\n",
      "Epoch 429/1000\n",
      "49/49 [==============================] - 14s 289ms/step - loss: 242.0631 - val_loss: 677.1201 - _timestamp: 1654093629.0000 - _runtime: 5538.0000\n",
      "Epoch 430/1000\n",
      "49/49 [==============================] - 15s 310ms/step - loss: 238.0824 - val_loss: 470.5288 - _timestamp: 1654093650.0000 - _runtime: 5559.0000\n",
      "Epoch 431/1000\n",
      "49/49 [==============================] - 15s 295ms/step - loss: 193.2702 - val_loss: 832.4883 - _timestamp: 1654093665.0000 - _runtime: 5574.0000\n",
      "Epoch 432/1000\n",
      "49/49 [==============================] - 15s 303ms/step - loss: 260.4330 - val_loss: 445.7497 - _timestamp: 1654093686.0000 - _runtime: 5595.0000\n",
      "Epoch 433/1000\n",
      "49/49 [==============================] - 13s 272ms/step - loss: 261.2592 - val_loss: 581.5186 - _timestamp: 1654093699.0000 - _runtime: 5608.0000\n",
      "Epoch 434/1000\n",
      "49/49 [==============================] - 13s 266ms/step - loss: 220.5717 - val_loss: 660.5789 - _timestamp: 1654093712.0000 - _runtime: 5621.0000\n",
      "Epoch 435/1000\n",
      "49/49 [==============================] - 13s 272ms/step - loss: 202.7987 - val_loss: 1058.8048 - _timestamp: 1654093726.0000 - _runtime: 5635.0000\n",
      "Epoch 436/1000\n",
      "49/49 [==============================] - 14s 282ms/step - loss: 220.8583 - val_loss: 282.9482 - _timestamp: 1654093747.0000 - _runtime: 5656.0000\n",
      "Epoch 437/1000\n",
      "49/49 [==============================] - 15s 304ms/step - loss: 209.7406 - val_loss: 553.6364 - _timestamp: 1654093762.0000 - _runtime: 5671.0000\n",
      "Epoch 438/1000\n",
      "49/49 [==============================] - 15s 301ms/step - loss: 190.3685 - val_loss: 484.9032 - _timestamp: 1654093782.0000 - _runtime: 5691.0000\n",
      "Epoch 439/1000\n",
      "49/49 [==============================] - 15s 308ms/step - loss: 228.1643 - val_loss: 380.5252 - _timestamp: 1654093797.0000 - _runtime: 5706.0000\n",
      "Epoch 440/1000\n",
      "49/49 [==============================] - 14s 287ms/step - loss: 154.1066 - val_loss: 664.7957 - _timestamp: 1654093811.0000 - _runtime: 5720.0000\n",
      "Epoch 441/1000\n",
      "49/49 [==============================] - 15s 297ms/step - loss: 194.4240 - val_loss: 492.3185 - _timestamp: 1654093833.0000 - _runtime: 5742.0000\n",
      "Epoch 442/1000\n",
      "49/49 [==============================] - 15s 306ms/step - loss: 258.7350 - val_loss: 503.7533 - _timestamp: 1654093853.0000 - _runtime: 5762.0000\n",
      "Epoch 443/1000\n",
      "49/49 [==============================] - 14s 289ms/step - loss: 274.7619 - val_loss: 181.4737 - _timestamp: 1654093868.0000 - _runtime: 5777.0000\n",
      "Epoch 444/1000\n",
      "49/49 [==============================] - 15s 299ms/step - loss: 221.1034 - val_loss: 279.0374 - _timestamp: 1654093883.0000 - _runtime: 5792.0000\n",
      "Epoch 445/1000\n",
      "49/49 [==============================] - 15s 315ms/step - loss: 270.1180 - val_loss: 399.1050 - _timestamp: 1654093904.0000 - _runtime: 5813.0000\n",
      "Epoch 446/1000\n",
      "49/49 [==============================] - 15s 304ms/step - loss: 301.3801 - val_loss: 842.6797 - _timestamp: 1654093924.0000 - _runtime: 5833.0000\n",
      "Epoch 447/1000\n",
      "49/49 [==============================] - 15s 306ms/step - loss: 311.6148 - val_loss: 515.2427 - _timestamp: 1654093939.0000 - _runtime: 5848.0000\n",
      "Epoch 448/1000\n",
      "49/49 [==============================] - 15s 297ms/step - loss: 278.1046 - val_loss: 961.8314 - _timestamp: 1654093954.0000 - _runtime: 5863.0000\n",
      "Epoch 449/1000\n",
      "49/49 [==============================] - 15s 304ms/step - loss: 300.5703 - val_loss: 198.0220 - _timestamp: 1654093969.0000 - _runtime: 5878.0000\n",
      "Epoch 450/1000\n",
      "49/49 [==============================] - 15s 298ms/step - loss: 271.3095 - val_loss: 1186.2235 - _timestamp: 1654093983.0000 - _runtime: 5892.0000\n",
      "Epoch 451/1000\n",
      "49/49 [==============================] - 14s 294ms/step - loss: 215.7496 - val_loss: 321.5526 - _timestamp: 1654093998.0000 - _runtime: 5907.0000\n",
      "Epoch 452/1000\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 213.9228 - val_loss: 287.0284 - _timestamp: 1654094012.0000 - _runtime: 5921.0000\n",
      "Epoch 453/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 218.3319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 54s 1s/step - loss: 218.3319 - val_loss: 126.0706 - _timestamp: 1654094027.0000 - _runtime: 5936.0000\n",
      "Epoch 454/1000\n",
      "49/49 [==============================] - 9s 187ms/step - loss: 234.4474 - val_loss: 929.9450 - _timestamp: 1654094075.0000 - _runtime: 5984.0000\n",
      "Epoch 455/1000\n",
      "49/49 [==============================] - 9s 189ms/step - loss: 253.2283 - val_loss: 460.5465 - _timestamp: 1654094085.0000 - _runtime: 5994.0000\n",
      "Epoch 456/1000\n",
      "49/49 [==============================] - 11s 215ms/step - loss: 269.5876 - val_loss: 403.3936 - _timestamp: 1654094096.0000 - _runtime: 6005.0000\n",
      "Epoch 457/1000\n",
      "49/49 [==============================] - 9s 180ms/step - loss: 315.8256 - val_loss: 797.3604 - _timestamp: 1654094105.0000 - _runtime: 6014.0000\n",
      "Epoch 458/1000\n",
      "49/49 [==============================] - 9s 177ms/step - loss: 291.8016 - val_loss: 479.3569 - _timestamp: 1654094114.0000 - _runtime: 6023.0000\n",
      "Epoch 459/1000\n",
      "49/49 [==============================] - 12s 242ms/step - loss: 288.2608 - val_loss: 348.9520 - _timestamp: 1654094127.0000 - _runtime: 6036.0000\n",
      "Epoch 460/1000\n",
      "49/49 [==============================] - 17s 343ms/step - loss: 336.7207 - val_loss: 1741.3124 - _timestamp: 1654094144.0000 - _runtime: 6053.0000\n",
      "Epoch 461/1000\n",
      "49/49 [==============================] - 18s 359ms/step - loss: 271.7690 - val_loss: 1121.6411 - _timestamp: 1654094162.0000 - _runtime: 6071.0000\n",
      "Epoch 462/1000\n",
      "49/49 [==============================] - 14s 292ms/step - loss: 221.7235 - val_loss: 481.5085 - _timestamp: 1654094176.0000 - _runtime: 6085.0000\n",
      "Epoch 463/1000\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 257.8035 - val_loss: 515.4600 - _timestamp: 1654094196.0000 - _runtime: 6105.0000\n",
      "Epoch 464/1000\n",
      "49/49 [==============================] - 14s 294ms/step - loss: 266.6594 - val_loss: 401.6586 - _timestamp: 1654094217.0000 - _runtime: 6126.0000\n",
      "Epoch 465/1000\n",
      "49/49 [==============================] - 15s 303ms/step - loss: 244.9346 - val_loss: 655.0145 - _timestamp: 1654094232.0000 - _runtime: 6141.0000\n",
      "Epoch 466/1000\n",
      "49/49 [==============================] - 15s 302ms/step - loss: 281.8965 - val_loss: 460.9713 - _timestamp: 1654094247.0000 - _runtime: 6156.0000\n",
      "Epoch 467/1000\n",
      "49/49 [==============================] - 15s 299ms/step - loss: 243.6276 - val_loss: 1002.9547 - _timestamp: 1654094262.0000 - _runtime: 6171.0000\n",
      "Epoch 468/1000\n",
      "49/49 [==============================] - 15s 296ms/step - loss: 266.7109 - val_loss: 849.5893 - _timestamp: 1654094277.0000 - _runtime: 6186.0000\n",
      "Epoch 469/1000\n",
      "49/49 [==============================] - 15s 302ms/step - loss: 231.9340 - val_loss: 497.3697 - _timestamp: 1654094297.0000 - _runtime: 6206.0000\n",
      "Epoch 470/1000\n",
      "49/49 [==============================] - 13s 264ms/step - loss: 263.9410 - val_loss: 637.6012 - _timestamp: 1654094316.0000 - _runtime: 6225.0000\n",
      "Epoch 471/1000\n",
      "49/49 [==============================] - 14s 286ms/step - loss: 346.8786 - val_loss: 817.8500 - _timestamp: 1654094330.0000 - _runtime: 6239.0000\n",
      "Epoch 472/1000\n",
      "49/49 [==============================] - 15s 298ms/step - loss: 232.9383 - val_loss: 653.3854 - _timestamp: 1654094351.0000 - _runtime: 6260.0000\n",
      "Epoch 473/1000\n",
      "49/49 [==============================] - 14s 292ms/step - loss: 240.5102 - val_loss: 829.9505 - _timestamp: 1654094371.0000 - _runtime: 6280.0000\n",
      "Epoch 474/1000\n",
      "49/49 [==============================] - 15s 300ms/step - loss: 222.1272 - val_loss: 762.9349 - _timestamp: 1654094386.0000 - _runtime: 6295.0000\n",
      "Epoch 475/1000\n",
      "49/49 [==============================] - 14s 295ms/step - loss: 280.3115 - val_loss: 717.7244 - _timestamp: 1654094401.0000 - _runtime: 6310.0000\n",
      "Epoch 476/1000\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 274.4186 - val_loss: 587.9734 - _timestamp: 1654094420.0000 - _runtime: 6329.0000\n",
      "Epoch 477/1000\n",
      "49/49 [==============================] - 14s 279ms/step - loss: 244.4512 - val_loss: 562.5814 - _timestamp: 1654094441.0000 - _runtime: 6350.0000\n",
      "Epoch 478/1000\n",
      "49/49 [==============================] - 14s 296ms/step - loss: 236.3198 - val_loss: 753.2081 - _timestamp: 1654094462.0000 - _runtime: 6371.0000\n",
      "Epoch 479/1000\n",
      "49/49 [==============================] - 15s 295ms/step - loss: 248.0858 - val_loss: 783.7834 - _timestamp: 1654094477.0000 - _runtime: 6386.0000\n",
      "Epoch 480/1000\n",
      "49/49 [==============================] - 16s 316ms/step - loss: 248.3029 - val_loss: 661.6075 - _timestamp: 1654094498.0000 - _runtime: 6407.0000\n",
      "Epoch 481/1000\n",
      "49/49 [==============================] - 13s 272ms/step - loss: 268.5580 - val_loss: 649.7076 - _timestamp: 1654094517.0000 - _runtime: 6426.0000\n",
      "Epoch 482/1000\n",
      "49/49 [==============================] - 13s 258ms/step - loss: 228.9536 - val_loss: 809.1146 - _timestamp: 1654094529.0000 - _runtime: 6438.0000\n",
      "Epoch 483/1000\n",
      "49/49 [==============================] - 16s 322ms/step - loss: 249.5589 - val_loss: 1112.2391 - _timestamp: 1654094545.0000 - _runtime: 6454.0000\n",
      "Epoch 484/1000\n",
      "49/49 [==============================] - 16s 318ms/step - loss: 238.0417 - val_loss: 691.5079 - _timestamp: 1654094561.0000 - _runtime: 6470.0000\n",
      "Epoch 485/1000\n",
      "49/49 [==============================] - 14s 283ms/step - loss: 264.0898 - val_loss: 1185.9109 - _timestamp: 1654094575.0000 - _runtime: 6484.0000\n",
      "Epoch 486/1000\n",
      "49/49 [==============================] - 16s 319ms/step - loss: 227.1563 - val_loss: 537.4954 - _timestamp: 1654094591.0000 - _runtime: 6500.0000\n",
      "Epoch 487/1000\n",
      "49/49 [==============================] - 16s 328ms/step - loss: 224.3254 - val_loss: 280.4406 - _timestamp: 1654094607.0000 - _runtime: 6516.0000\n",
      "Epoch 488/1000\n",
      "49/49 [==============================] - 16s 321ms/step - loss: 222.8969 - val_loss: 613.5599 - _timestamp: 1654094623.0000 - _runtime: 6532.0000\n",
      "Epoch 489/1000\n",
      "49/49 [==============================] - 13s 256ms/step - loss: 254.0367 - val_loss: 721.0070 - _timestamp: 1654094636.0000 - _runtime: 6545.0000\n",
      "Epoch 490/1000\n",
      "49/49 [==============================] - 15s 306ms/step - loss: 233.1438 - val_loss: 1189.9875 - _timestamp: 1654094659.0000 - _runtime: 6568.0000\n",
      "Epoch 491/1000\n",
      "49/49 [==============================] - 14s 288ms/step - loss: 274.1172 - val_loss: 1412.1794 - _timestamp: 1654094678.0000 - _runtime: 6587.0000\n",
      "Epoch 492/1000\n",
      "49/49 [==============================] - 15s 302ms/step - loss: 327.9872 - val_loss: 460.6354 - _timestamp: 1654094699.0000 - _runtime: 6608.0000\n",
      "Epoch 493/1000\n",
      "49/49 [==============================] - 15s 310ms/step - loss: 234.3260 - val_loss: 681.7414 - _timestamp: 1654094715.0000 - _runtime: 6624.0000\n",
      "Epoch 494/1000\n",
      "49/49 [==============================] - 15s 313ms/step - loss: 236.2166 - val_loss: 400.0265 - _timestamp: 1654094730.0000 - _runtime: 6639.0000\n",
      "Epoch 495/1000\n",
      "49/49 [==============================] - 15s 303ms/step - loss: 224.2096 - val_loss: 883.1534 - _timestamp: 1654094750.0000 - _runtime: 6659.0000\n",
      "Epoch 496/1000\n",
      "49/49 [==============================] - 14s 291ms/step - loss: 255.0038 - val_loss: 586.3200 - _timestamp: 1654094765.0000 - _runtime: 6674.0000\n",
      "Epoch 497/1000\n",
      "49/49 [==============================] - 13s 273ms/step - loss: 211.1360 - val_loss: 367.8987 - _timestamp: 1654094778.0000 - _runtime: 6687.0000\n",
      "Epoch 498/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 211.5590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 121s 3s/step - loss: 211.5590 - val_loss: 118.8103 - _timestamp: 1654094793.0000 - _runtime: 6702.0000\n",
      "Epoch 499/1000\n",
      "49/49 [==============================] - 47s 432ms/step - loss: 273.0768 - val_loss: 895.6631 - _timestamp: 1654094967.0000 - _runtime: 6876.0000\n",
      "Epoch 500/1000\n",
      "49/49 [==============================] - 17s 350ms/step - loss: 240.9929 - val_loss: 683.8648 - _timestamp: 1654095020.0000 - _runtime: 6929.0000\n",
      "Epoch 501/1000\n",
      "49/49 [==============================] - 17s 337ms/step - loss: 225.0890 - val_loss: 592.3585 - _timestamp: 1654095040.0000 - _runtime: 6949.0000\n",
      "Epoch 502/1000\n",
      "49/49 [==============================] - 18s 372ms/step - loss: 191.3008 - val_loss: 256.9822 - _timestamp: 1654095058.0000 - _runtime: 6967.0000\n",
      "Epoch 503/1000\n",
      "49/49 [==============================] - 17s 336ms/step - loss: 254.6874 - val_loss: 971.3177 - _timestamp: 1654095075.0000 - _runtime: 6984.0000\n",
      "Epoch 504/1000\n",
      "49/49 [==============================] - 18s 355ms/step - loss: 213.2980 - val_loss: 466.0132 - _timestamp: 1654095096.0000 - _runtime: 7005.0000\n",
      "Epoch 505/1000\n",
      "49/49 [==============================] - 17s 347ms/step - loss: 224.4981 - val_loss: 363.1854 - _timestamp: 1654095116.0000 - _runtime: 7025.0000\n",
      "Epoch 506/1000\n",
      "49/49 [==============================] - 19s 391ms/step - loss: 242.1261 - val_loss: 168.5029 - _timestamp: 1654095136.0000 - _runtime: 7045.0000\n",
      "Epoch 507/1000\n",
      "49/49 [==============================] - 17s 339ms/step - loss: 364.0762 - val_loss: 387.0592 - _timestamp: 1654095154.0000 - _runtime: 7063.0000\n",
      "Epoch 508/1000\n",
      "49/49 [==============================] - 18s 370ms/step - loss: 307.7155 - val_loss: 499.9821 - _timestamp: 1654095172.0000 - _runtime: 7081.0000\n",
      "Epoch 509/1000\n",
      "49/49 [==============================] - 18s 373ms/step - loss: 202.9283 - val_loss: 204.0721 - _timestamp: 1654095191.0000 - _runtime: 7100.0000\n",
      "Epoch 510/1000\n",
      "49/49 [==============================] - 17s 343ms/step - loss: 207.2217 - val_loss: 608.9990 - _timestamp: 1654095210.0000 - _runtime: 7119.0000\n",
      "Epoch 511/1000\n",
      "49/49 [==============================] - 17s 341ms/step - loss: 294.3409 - val_loss: 646.6368 - _timestamp: 1654095227.0000 - _runtime: 7136.0000\n",
      "Epoch 512/1000\n",
      "49/49 [==============================] - 17s 338ms/step - loss: 210.8435 - val_loss: 172.8473 - _timestamp: 1654095243.0000 - _runtime: 7152.0000\n",
      "Epoch 513/1000\n",
      "49/49 [==============================] - 17s 344ms/step - loss: 230.4796 - val_loss: 231.1319 - _timestamp: 1654095264.0000 - _runtime: 7173.0000\n",
      "Epoch 514/1000\n",
      "49/49 [==============================] - 17s 344ms/step - loss: 254.5451 - val_loss: 279.0512 - _timestamp: 1654095281.0000 - _runtime: 7190.0000\n",
      "Epoch 515/1000\n",
      "49/49 [==============================] - 17s 341ms/step - loss: 222.0997 - val_loss: 2539.7678 - _timestamp: 1654095301.0000 - _runtime: 7210.0000\n",
      "Epoch 516/1000\n",
      "49/49 [==============================] - 17s 335ms/step - loss: 183.3888 - val_loss: 279.9704 - _timestamp: 1654095318.0000 - _runtime: 7227.0000\n",
      "Epoch 517/1000\n",
      "49/49 [==============================] - 17s 342ms/step - loss: 218.9522 - val_loss: 933.1898 - _timestamp: 1654095339.0000 - _runtime: 7248.0000\n",
      "Epoch 518/1000\n",
      "49/49 [==============================] - 16s 337ms/step - loss: 226.0218 - val_loss: 179.6211 - _timestamp: 1654095355.0000 - _runtime: 7264.0000\n",
      "Epoch 519/1000\n",
      "49/49 [==============================] - 16s 323ms/step - loss: 274.2486 - val_loss: 294.9636 - _timestamp: 1654095375.0000 - _runtime: 7284.0000\n",
      "Epoch 520/1000\n",
      "49/49 [==============================] - 18s 361ms/step - loss: 220.7174 - val_loss: 239.4875 - _timestamp: 1654095393.0000 - _runtime: 7302.0000\n",
      "Epoch 521/1000\n",
      "49/49 [==============================] - 18s 371ms/step - loss: 223.3966 - val_loss: 383.4622 - _timestamp: 1654095411.0000 - _runtime: 7320.0000\n",
      "Epoch 522/1000\n",
      "49/49 [==============================] - 18s 364ms/step - loss: 215.6320 - val_loss: 476.5309 - _timestamp: 1654095432.0000 - _runtime: 7341.0000\n",
      "Epoch 523/1000\n",
      "49/49 [==============================] - 17s 340ms/step - loss: 253.0208 - val_loss: 287.7140 - _timestamp: 1654095451.0000 - _runtime: 7360.0000\n",
      "Epoch 524/1000\n",
      "49/49 [==============================] - 18s 372ms/step - loss: 248.0699 - val_loss: 153.2481 - _timestamp: 1654095469.0000 - _runtime: 7378.0000\n",
      "Epoch 525/1000\n",
      "49/49 [==============================] - 18s 364ms/step - loss: 262.8217 - val_loss: 153.6300 - _timestamp: 1654095487.0000 - _runtime: 7396.0000\n",
      "Epoch 526/1000\n",
      "49/49 [==============================] - 18s 360ms/step - loss: 211.3118 - val_loss: 894.2893 - _timestamp: 1654095505.0000 - _runtime: 7414.0000\n",
      "Epoch 527/1000\n",
      "49/49 [==============================] - 16s 331ms/step - loss: 242.1134 - val_loss: 345.9548 - _timestamp: 1654095521.0000 - _runtime: 7430.0000\n",
      "Epoch 528/1000\n",
      "49/49 [==============================] - 18s 364ms/step - loss: 227.2285 - val_loss: 168.2172 - _timestamp: 1654095543.0000 - _runtime: 7452.0000\n",
      "Epoch 529/1000\n",
      "49/49 [==============================] - ETA: 0s - loss: 232.9463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/demand_forecasting/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb91f7340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3bb9182130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 130s 3s/step - loss: 232.9463 - val_loss: 109.2989 - _timestamp: 1654095561.0000 - _runtime: 7470.0000\n",
      "Epoch 530/1000\n",
      "49/49 [==============================] - 18s 363ms/step - loss: 251.7414 - val_loss: 364.6102 - _timestamp: 1654095691.0000 - _runtime: 7600.0000\n",
      "Epoch 531/1000\n",
      "49/49 [==============================] - 18s 372ms/step - loss: 225.1179 - val_loss: 153.8731 - _timestamp: 1654095712.0000 - _runtime: 7621.0000\n",
      "Epoch 532/1000\n",
      "49/49 [==============================] - 17s 344ms/step - loss: 275.5646 - val_loss: 1330.5027 - _timestamp: 1654095729.0000 - _runtime: 7638.0000\n",
      "Epoch 533/1000\n",
      "49/49 [==============================] - 16s 333ms/step - loss: 264.0919 - val_loss: 426.6331 - _timestamp: 1654095746.0000 - _runtime: 7655.0000\n",
      "Epoch 534/1000\n",
      "49/49 [==============================] - 19s 379ms/step - loss: 246.9800 - val_loss: 139.9969 - _timestamp: 1654095764.0000 - _runtime: 7673.0000\n",
      "Epoch 535/1000\n",
      "49/49 [==============================] - 17s 339ms/step - loss: 210.5069 - val_loss: 1058.6919 - _timestamp: 1654095783.0000 - _runtime: 7692.0000\n",
      "Epoch 536/1000\n",
      "49/49 [==============================] - 17s 338ms/step - loss: 302.5299 - val_loss: 310.8810 - _timestamp: 1654095799.0000 - _runtime: 7708.0000\n",
      "Epoch 537/1000\n",
      "49/49 [==============================] - 15s 314ms/step - loss: 269.9344 - val_loss: 548.3243 - _timestamp: 1654095819.0000 - _runtime: 7728.0000\n",
      "Epoch 538/1000\n",
      "49/49 [==============================] - 16s 320ms/step - loss: 233.4346 - val_loss: 1344.3232 - _timestamp: 1654095834.0000 - _runtime: 7743.0000\n",
      "Epoch 539/1000\n",
      "49/49 [==============================] - 17s 350ms/step - loss: 231.6242 - val_loss: 542.6185 - _timestamp: 1654095856.0000 - _runtime: 7765.0000\n",
      "Epoch 540/1000\n",
      "49/49 [==============================] - 19s 387ms/step - loss: 214.7532 - val_loss: 378.9490 - _timestamp: 1654095873.0000 - _runtime: 7782.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_set,\n",
    "    validation_data=valid_set,\n",
    "    epochs=1000,\n",
    "    callbacks=[WandbCallback(), earlystopping_cb, checkpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "384cc7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6aaec",
   "metadata": {},
   "source": [
    "### Price Optimization Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5918e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_week(model, data):\n",
    "    pred = model.predict(data)[0][0]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "def forecast(model, data, prices, window_size=config.window_size, batch_size=config.batch_size, buffer_size=config.buffer_size):\n",
    "    data = data[['scaled_sales', 'scaled_price', 'sales']].copy()\n",
    "    predictions = []\n",
    "    for price in prices:\n",
    "        data = data.append({'scaled_sales':0, 'scaled_price': scaler.transform([[0, price]])[0, 1]}, ignore_index = True)\n",
    "        current_week = create_windowed_dataset(data.iloc[-(config.batch_size + config.window_size):], with_label=True)\n",
    "        next_week_sales = predict_next_week(model, current_week)\n",
    "        predictions.append(next_week_sales)\n",
    "        data['sales'].iloc[-1] = next_week_sales\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0845b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 16:56:41.459996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-03 16:56:41.481998: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-03 16:56:41.491421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (manfred): /proc/driver/nvidia/version does not exist\n",
      "2022-06-03 16:56:41.779048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model(\"../model/demand_forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4471c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils3 import ModelPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7e572e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelPipeline:\n",
    "#     def __init__(self, model, data_pipeline):\n",
    "#         self.model = model\n",
    "#         self.data_pipeline = data_pipeline\n",
    "        \n",
    "#     def predict_next_week(self, model, data):\n",
    "#         return self.model.predict(data)[0][0]\n",
    "\n",
    "#     def forecast(self, data, prices):\n",
    "#         data = self.data_pipeline.rescale(data)\n",
    "#         data = data[['scaled_sales', 'scaled_price', 'sales']].copy()\n",
    "#         predictions = []\n",
    "#         for price in prices:\n",
    "#             data = data.append({'scaled_sales':0, 'scaled_price': self.data_pipeline.scaler.transform([[0, price]])[0, 1]}, ignore_index = True)\n",
    "#             current_week = self.data_pipeline.create_windowed_dataset(data.iloc[-(self.data_pipeline.batch_size + self.data_pipeline.window_size):], with_label=True, rescale=False)\n",
    "#             next_week_sales = self.predict_next_week(self.model, current_week)\n",
    "#             predictions.append(next_week_sales)\n",
    "#             data['sales'].iloc[-1] = next_week_sales\n",
    "\n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a78ea3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ModelPipeline(model, data_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfbc4457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://08a16ca7-e382-451a-b818-52ac47cafd4d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://08a16ca7-e382-451a-b818-52ac47cafd4d/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efcafff4c70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7efcafb8b820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/demand_forecasting/pipeline.joblib']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, \"../model/demand_forecasting/pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96bd76bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/manfred/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_sales \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mforecast(valid, [\u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                           \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                           \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                           \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \u001b[38;5;241m312089.685355\u001b[39m, \n\u001b[1;32m      5\u001b[0m                                          ])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_sales\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(predicted_sales))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py:2262\u001b[0m, in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39mgca)\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgca\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/figure.py:1515\u001b[0m, in \u001b[0;36mFigureBase.gca\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1507\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling gca() with keyword arguments was deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes with non-default arguments, use plt.axes() or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.subplot().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack\u001b[38;5;241m.\u001b[39mempty():\n\u001b[0;32m-> 1515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m    770\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 772\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43msubplot_class_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojection_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axes_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# This will also update the axes position.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subplotspec(SubplotSpec\u001b[38;5;241m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    451\u001b[0m     warn_deprecated(\n\u001b[1;32m    452\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:621\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# placeholder for any colorbars added that use this Axes.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# (see colorbar.py):\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_colorbars \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines \u001b[38;5;241m=\u001b[39m mspines\u001b[38;5;241m.\u001b[39mSpines\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_axes_spines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# this call may differ for non-sep axes, e.g., polar\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_axis()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:1141\u001b[0m, in \u001b[0;36m_AxesBase._gen_axes_spines\u001b[0;34m(self, locations, offset, units)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_axes_spines\u001b[39m(\u001b[38;5;28mself\u001b[39m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minches\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    Intended to be overridden by new projection types.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOrderedDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmspines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_spine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbottom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:1141\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_axes_spines\u001b[39m(\u001b[38;5;28mself\u001b[39m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minches\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    Intended to be overridden by new projection types.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict((side, \u001b[43mmspines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_spine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1142\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m side \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/spines.py:437\u001b[0m, in \u001b[0;36mSpine.linear_spine\u001b[0;34m(cls, axes, spine_type, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munable to make path for spine \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m spine_type)\n\u001b[0;32m--> 437\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspine_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m result\u001b[38;5;241m.\u001b[39mset_visible(rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.spines.\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spine_type)])\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/spines.py:72\u001b[0m, in \u001b[0;36mSpine.__init__\u001b[0;34m(self, axes, spine_type, path, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Defer initial position determination. (Not much support for\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# non-rectangular axes is currently implemented, and this lets\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# them pass through the spines machinery without errors.)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m _api\u001b[38;5;241m.\u001b[39mcheck_isinstance(\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241m.\u001b[39mPath, path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# To support drawing both linear and circular spines, this\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# class implements Patch behavior three ways. If\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# self._patch_type == 'line', behave like a mpatches.PathPatch\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# instance. If self._patch_type == 'circle', behave like a\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# mpatches.Ellipse instance. If self._patch_type == 'arc', behave like\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# a mpatches.Arc instance.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/_api/__init__.py:222\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'path'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_sales = pipeline.forecast(valid, [312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, \n",
    "                                         ])\n",
    "plt.plot(predicted_sales)\n",
    "print(np.mean(predicted_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c566768",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# No discount at all\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# predicted_sales = forecast(model, valid, [312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#                                          ])\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_sales\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(predicted_sales))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py:2262\u001b[0m, in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39mgca)\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgca\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/figure.py:1515\u001b[0m, in \u001b[0;36mFigureBase.gca\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1507\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling gca() with keyword arguments was deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes with non-default arguments, use plt.axes() or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.subplot().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack\u001b[38;5;241m.\u001b[39mempty():\n\u001b[0;32m-> 1515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axstack()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m    770\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 772\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43msubplot_class_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojection_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axes_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# This will also update the axes position.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subplotspec(SubplotSpec\u001b[38;5;241m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    451\u001b[0m     warn_deprecated(\n\u001b[1;32m    452\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:621\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# placeholder for any colorbars added that use this Axes.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# (see colorbar.py):\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_colorbars \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines \u001b[38;5;241m=\u001b[39m mspines\u001b[38;5;241m.\u001b[39mSpines\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_axes_spines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# this call may differ for non-sep axes, e.g., polar\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_axis()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:1141\u001b[0m, in \u001b[0;36m_AxesBase._gen_axes_spines\u001b[0;34m(self, locations, offset, units)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_axes_spines\u001b[39m(\u001b[38;5;28mself\u001b[39m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minches\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    Intended to be overridden by new projection types.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOrderedDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmspines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_spine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbottom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/axes/_base.py:1141\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_axes_spines\u001b[39m(\u001b[38;5;28mself\u001b[39m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minches\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    Intended to be overridden by new projection types.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict((side, \u001b[43mmspines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_spine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1142\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m side \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/spines.py:437\u001b[0m, in \u001b[0;36mSpine.linear_spine\u001b[0;34m(cls, axes, spine_type, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munable to make path for spine \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m spine_type)\n\u001b[0;32m--> 437\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspine_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m result\u001b[38;5;241m.\u001b[39mset_visible(rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.spines.\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(spine_type)])\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/spines.py:72\u001b[0m, in \u001b[0;36mSpine.__init__\u001b[0;34m(self, axes, spine_type, path, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Defer initial position determination. (Not much support for\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# non-rectangular axes is currently implemented, and this lets\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# them pass through the spines machinery without errors.)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m _api\u001b[38;5;241m.\u001b[39mcheck_isinstance(\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241m.\u001b[39mPath, path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# To support drawing both linear and circular spines, this\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# class implements Patch behavior three ways. If\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# self._patch_type == 'line', behave like a mpatches.PathPatch\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# instance. If self._patch_type == 'circle', behave like a\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# mpatches.Ellipse instance. If self._patch_type == 'arc', behave like\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# a mpatches.Arc instance.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/_api/__init__.py:222\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'path'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# No discount at all\n",
    "# predicted_sales = forecast(model, valid, [312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355,\n",
    "#                                           312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, \n",
    "#                                          ])\n",
    "plt.plot(predicted_sales)\n",
    "print(np.mean(predicted_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4afb1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No discount at all\n",
    "predicted_sales = forecast(model, valid, [312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 300000.685355, 300000.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 300000.685355, 300000.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 300000.685355, 300000.685355,\n",
    "                                          312089.685355, 312089.685355, 312089.685355, 312089.685355, 312089.685355, 300000.685355, 300000.685355,\n",
    "                                         ])\n",
    "plt.plot(predicted_sales)\n",
    "print(np.mean(predicted_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount on the first 2 weeks\n",
    "predicted_sales = forecast(model, valid, [0, 0, 0, 0, 0, 0, 0,\n",
    "                                          0, 0, 0, 0, 0, 0, 0,\n",
    "                                          0, 0, 0, 0, 0, 0, 0,\n",
    "                                          0, 0, 0, 0, 0, 0, 0,\n",
    "                                         ])\n",
    "plt.plot(predicted_sales)\n",
    "print(np.mean(predicted_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
